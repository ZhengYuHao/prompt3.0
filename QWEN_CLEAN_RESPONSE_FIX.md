# 千问模型响应清理修复

## 问题描述

千问模型（qwen3-32b-lb-pv）在响应中可能输出格式标签（如 `<|im_start|>`、`<|im_end|>`），这些标签会污染数据，影响后续使用。

### 典型影响

- **代码生成**：标签混入代码，导致语法错误
- **数据解析**：干扰 JSON/YAML 等结构化数据的解析
- **HTML 渲染**：标签可能被浏览器错误解释
- **存储污染**：格式标签被保存到历史记录和 HTML 报告

---

## 修复方案

### 1. 添加响应清理函数

**文件**: `llm_client.py:142-169`

```python
def _clean_llm_response(self, content: str) -> str:
    """
    清理 LLM 响应中的格式标签和脏数据

    Args:
        content: 原始 LLM 响应内容

    Returns:
        清理后的内容
    """
    import re

    # 移除完整的格式标签（包括角色名）
    # 匹配格式：<|im_start|>role 或 <|im_end|>
    patterns_to_remove = [
        r'<\|im_start\|>\s*\w+\s*',  # <|im_start|>role 格式
        r'<\|im_end\|>',              # <|im_end|> 格式
        r'<\|.*?\|>',                 # 其他 <|xxx|> 格式的标签
    ]

    cleaned = content
    for pattern in patterns_to_remove:
        cleaned = re.sub(pattern, '', cleaned)

    # 清理多余的空白字符
    cleaned = re.sub(r'\n\s*\n', '\n\n', cleaned)  # 多个空行变成两个
    cleaned = cleaned.strip()

    return cleaned
```

### 2. 在响应提取后立即清理

**文件**: `llm_client.py:245-248`

```python
content = (resp.choices[0].message.content or "").strip()

# 清理响应中的格式标签和脏数据
content = self._clean_llm_response(content)
```

### 3. 增强抑制指令

在系统提示词中添加禁止格式标签的指令：

```python
# 如果是千问模型，在系统提示词中添加强抑制指令
if "qwen" in _model.lower():
    suppress_thought = """

【禁止输出思考过程】
- 直接输出最终结果
- 严禁输出推理步骤、思考过程或中间想法
- 严禁使用"好的"、"我现在需要"、"接下来"等引导词
- 严禁输出任何格式标签如 <|im_start|> 或 <|im_end|>
- 只输出符合要求格式的内容
- 输出必须简洁精确
"""
    system_prompt = system_prompt + suppress_thought
```

---

## 清理规则

| 输入示例 | 输出结果 | 说明 |
|---------|---------|------|
| `<|im_start|>system<|im_end|>` | (空字符串) | 完整的格式标签被移除 |
| `<|im_start|>user<|im_end|>你好` | `你好` | 保留实际内容，移除标签 |
| `<|im_start|>assistant<|im_end|>回复内容` | `回复内容` | 保留回复内容 |
| `<|im_start|>role_name` | (空字符串) | 移除标签和角色名 |
| 正常代码 | 正常代码 | 不影响无标签内容 |

---

## 测试验证

### 测试文件

`test_clean_response.py`

### 测试结果

```
======================================================================
LLM 响应清理功能测试
======================================================================

【测试 1】包含标准格式标签
----------------------------------------------------------------------
✅ 通过

【测试 2】包含多个格式标签
----------------------------------------------------------------------
✅ 通过

【测试 3】正常代码（无标签）
----------------------------------------------------------------------
✅ 通过

【测试 4】多余的换行
----------------------------------------------------------------------
✅ 通过

【测试 5】完整的对话格式
----------------------------------------------------------------------
✅ 通过

======================================================================
测试完成: 5/5 通过
✅ 所有测试通过

======================================================================
【测试真实 LLM 调用】
======================================================================

响应长度: 72 字符

响应内容:

```python
def add_numbers(a, b):
    return a + b
```

✅ 响应中无格式标签（清理成功）

======================================================================
✅ 所有测试通过
```

---

## 使用效果

### 修复前

```python
<|im_start|>system<|im_end|>

def add_numbers(a, b):
    return a + b<|im_start|>assistant<|im_end|>
```

### 修复后

```python

def add_numbers(a, b):
    return a + b
```

---

## 影响范围

✅ **自动生效**：所有 LLM 调用都会自动清理响应  
✅ **无副作用**：不影响无标签的正常内容  
✅ **向后兼容**：不改变 API 接口  
✅ **全面覆盖**：包括所有千问模型的调用  

---

## 相关文件

- **修复文件**: `llm_client.py:142-169` (清理函数), `llm_client.py:245-248` (调用位置)
- **测试文件**: `test_clean_response.py`
- **相关修复**: `QWEN_THOUGHT_SUPPRESS_FIX.md` (思考过程抑制)

---

## 未来改进

1. **更智能的清理**：识别并保留有效的格式信息
2. **配置化**：允许用户自定义清理规则
3. **日志记录**：记录清理操作，便于调试
4. **性能优化**：缓存编译后的正则表达式

---

**修复完成时间**: 2026-02-02

**修复状态**: ✅ 已完成并测试通过
