"""
å®Œæ•´æµæ°´çº¿æ¼”ç¤ºï¼šprompt_preprocessor.py + prompt_structurizer.py ååŒå·¥ä½œ
å±•ç¤ºä»å£è¯­åŒ–è¾“å…¥åˆ°ç»“æ„åŒ–æ¨¡æ¿çš„å®Œæ•´è½¬æ¢è¿‡ç¨‹

ä½¿ç”¨æ–¹æ³•:
1. ä½¿ç”¨é»˜è®¤è¾“å…¥: python3 demo_full_pipeline.py
2. ä»æ–‡ä»¶è¯»å–è¾“å…¥: python3 demo_full_pipeline.py <æ–‡ä»¶è·¯å¾„>
"""

import json
import re
import time
import sys
import os

# ============================================================================
# å¯¼å…¥é¡¹ç›®æ¨¡å—
# ============================================================================

from logger import info, warning, error
from dataclasses import asdict
from data_models import (
    ProcessingMode, Prompt10Result, StepSnapshot, get_timestamp, generate_id,
    create_prompt20_result, convert_prompt20_to_dsl_input
)

# å¯¼å…¥é¢„å¤„ç†æ¨¡å—ï¼ˆåŸ 1.pyï¼‰
from prompt_preprocessor import PromptPreprocessor

# å¯¼å…¥ç»“æ„åŒ–æ¨¡å—ï¼ˆåŸ 2.pyï¼‰
from prompt_structurizer import (
    PromptStructurizer,
    HallucinationFirewall,
    TypeCleaner,
    EntityConflictResolver,
    VariableMeta,
    LLMEntityExtractor  # çœŸå® LLM å®ä½“æŠ½å–å™¨
)

# å¯¼å…¥ DSL ç¼–è¯‘å™¨æ¨¡å—ï¼ˆåŸ prompt_dslcompiler.pyï¼‰
from prompt_dslcompiler import SelfCorrectionLoop, ValidationResult

# å¯¼å…¥ä»£ç ç”Ÿæˆå™¨æ¨¡å—ï¼ˆåŸ prompt_codegenetate.pyï¼‰
from prompt_codegenetate import WaActCompiler

# å¯¼å…¥å†å²è®°å½•ç®¡ç†
from history_manager import HistoryManager, PipelineHistory


# ============================================================================
# é…ç½®
# ============================================================================
# æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿ LLM å®¢æˆ·ç«¯ï¼ˆè®¾ä¸º True å¯é¿å…çœŸå® API è°ƒç”¨ï¼‰
USE_MOCK = False  # é»˜è®¤ä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯ï¼Œé¿å…æ„å¤– API è°ƒç”¨
# å¦‚æœè¦ä½¿ç”¨çœŸå® LLMï¼Œè¯·è®¾ç½®ä¸º False å¹¶ç¡®ä¿é…ç½®äº†æœ‰æ•ˆçš„ API å¯†é’¥
# USE_MOCK = False

# ============================================================================
# å¤æ‚æµ‹è¯•åœºæ™¯è®¾è®¡
# ============================================================================

# åŸå§‹å£è¯­åŒ–è¾“å…¥ï¼ˆæ•…æ„è®¾è®¡å¾—å¾ˆå£è¯­åŒ–ã€ä¸è§„èŒƒï¼‰
RAW_INPUT = """
å¸®æˆ‘è®¾è®¡ä¸€ä¸ªæ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œéœ€è¦å¤„ç†å¤šé¢†åŸŸçŸ¥è¯†åº“çš„æ£€ç´¢ä¸æ¨ç†ã€‚

é¦–å…ˆï¼Œç”¨æˆ·è¾“å…¥æŸ¥è¯¢åï¼Œç³»ç»Ÿéœ€è¦åˆ¤æ–­æŸ¥è¯¢ç±»å‹ï¼šå¦‚æœæ˜¯ç®€å•äº‹å®æŸ¥è¯¢ï¼Œèµ°å‘é‡æ£€ç´¢é€šé“ï¼›å¦‚æœæ˜¯å¤æ‚æ¨ç†æŸ¥è¯¢ï¼Œå…ˆè¿›è¡Œæ„å›¾åˆ†è§£ï¼Œå†èµ°å›¾æ•°æ®åº“æ£€ç´¢ï¼›å¦‚æœæ˜¯ä»£ç ç›¸å…³é—®é¢˜ï¼Œåˆ™è°ƒç”¨ä»£ç åˆ†æå¼•æ“ã€‚

å‘é‡æ£€ç´¢æ¨¡å¼ä¸‹ï¼Œå¦‚æœç›¸ä¼¼åº¦è¶…è¿‡0.85ï¼Œç›´æ¥è¿”å›top-3ç»“æœï¼›å¦åˆ™ç»“åˆé‡æ’åºæ¨¡å‹é‡æ–°è¯„åˆ†ï¼Œå†è¿”å›top-5ã€‚æ£€ç´¢å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°æ··åˆæ£€ç´¢æ¨¡å¼ã€‚

å›¾æ•°æ®åº“æ£€ç´¢æ—¶ï¼Œéœ€è¦æ²¿ç€çŸ¥è¯†å›¾è°±è¿›è¡Œ2è·³é‚»å±…æ¢ç´¢ï¼Œå¦‚æœæ‰¾åˆ°åŒ¹é…èŠ‚ç‚¹åˆ™è¿”å›ç›¸å…³å®ä½“å’Œå…³ç³»ï¼Œå¦åˆ™å›é€€åˆ°å…¨é‡æœç´¢ã€‚æ¯æ¬¡æŸ¥è¯¢éƒ½è¦ç¼“å­˜ç»“æœï¼Œç¼“å­˜æœ‰æ•ˆæœŸ30åˆ†é’Ÿã€‚

ä»£ç åˆ†æå¼•æ“æ”¯æŒPythonå’ŒJavaä»£ç ï¼Œå¦‚æœä»£ç è¡Œæ•°è¶…è¿‡500è¡Œï¼Œåªè¿›è¡Œé™æ€åˆ†æï¼›å¦‚æœå°‘äº500è¡Œï¼Œåˆ™è¿›è¡Œå®Œæ•´è¯­ä¹‰åˆ†æå¹¶ç”Ÿæˆè§£é‡Šæ–‡æ¡£ã€‚

ç”¨æˆ·åé¦ˆç¯èŠ‚ï¼šå¦‚æœç”¨æˆ·å¯¹ç»“æœä¸æ»¡æ„ï¼Œç‚¹å‡»"é‡æ–°ç”Ÿæˆ"æ—¶å¯ç”¨æ›´å¼ºçš„æ¨ç†æ¨¡å‹ï¼›å¦‚æœè¿ç»­3æ¬¡ä¸æ»¡æ„ï¼Œåˆ™è‡ªåŠ¨å‡çº§åˆ°äººå·¥å®¡æ ¸é˜Ÿåˆ—ã€‚

æ•°æ®æºé…ç½®ï¼šçŸ¥è¯†åº“AåŒ…å«2000ä¸ªåŒ»å­¦æ–‡æ¡£ï¼ŒçŸ¥è¯†åº“BåŒ…å«3000ä¸ªæŠ€æœ¯æ–‡æ¡£ï¼ŒçŸ¥è¯†åº“CåŒ…å«1500ä¸ªæ³•å¾‹æ–‡æ¡£ã€‚æ¯ä¸ªçŸ¥è¯†åº“éƒ½æœ‰ç‹¬ç«‹çš„å‘é‡ç´¢å¼•ï¼Œå‘é‡ç»´åº¦ç»Ÿä¸€ä¸º1536ã€‚

å¹¶å‘æ§åˆ¶ï¼šç³»ç»Ÿæ”¯æŒæœ€å¤§50ä¸ªå¹¶å‘è¯·æ±‚ï¼Œå¦‚æœè¶…è¿‡åˆ™æ’é˜Ÿç­‰å¾…ã€‚æ™®é€šç”¨æˆ·ä¼˜å…ˆçº§è®¾ä¸º1ï¼ŒVIPç”¨æˆ·ä¼˜å…ˆçº§è®¾ä¸º5ï¼Œç®¡ç†å‘˜ä¼˜å…ˆçº§è®¾ä¸º10ã€‚

å®‰å…¨ç­–ç•¥ï¼šæ‰€æœ‰æŸ¥è¯¢å†…å®¹ç»è¿‡æ•æ„Ÿè¯è¿‡æ»¤ï¼Œå¦‚æœæ£€æµ‹åˆ°è¿è§„å†…å®¹åˆ™æ‹’ç»æœåŠ¡å¹¶è®°å½•æ—¥å¿—ã€‚å¯¹äºé‡‘èç±»æŸ¥è¯¢ï¼Œéœ€è¦äºŒæ¬¡ç¡®è®¤ç”¨æˆ·èº«ä»½ã€‚

å“åº”æ—¶é—´è¦æ±‚ï¼šå‘é‡æ£€ç´¢è¦åœ¨500mså†…å®Œæˆï¼Œå›¾æ•°æ®åº“æ£€ç´¢åœ¨1ç§’å†…å®Œæˆï¼Œä»£ç åˆ†æåœ¨2ç§’å†…å®Œæˆã€‚æ€»å“åº”æ—¶é—´ä¸è¶…è¿‡3ç§’ï¼Œå¦åˆ™é™çº§æœåŠ¡ã€‚

æ—¥å¿—çº§åˆ«ï¼šé”™è¯¯æ—¥å¿—ä¿ç•™90å¤©ï¼Œè®¿é—®æ—¥å¿—ä¿ç•™30å¤©ï¼Œè°ƒè¯•æ—¥å¿—ä¿ç•™7å¤©ã€‚æ‰€æœ‰æ—¥å¿—éƒ½è¦ä¸Šä¼ åˆ°ä¸­å¤®æ—¥å¿—ç³»ç»Ÿã€‚

ç›‘æ§æŒ‡æ ‡ï¼šQPSã€å¹³å‡å“åº”æ—¶é—´ã€95åˆ†ä½å“åº”æ—¶é—´ã€ç¼“å­˜å‘½ä¸­ç‡ã€æ£€ç´¢å‡†ç¡®ç‡ã€‚å¦‚æœQPSä½äº10æŒç»­10åˆ†é’Ÿï¼Œè§¦å‘å‘Šè­¦ï¼›å¦‚æœ95åˆ†ä½å“åº”æ—¶é—´è¶…è¿‡3ç§’æŒç»­5åˆ†é’Ÿï¼Œè§¦å‘æ‰©å®¹ã€‚
""".strip()

# æœ¯è¯­æ˜ å°„è¡¨ï¼ˆprompt_preprocessor.py ä½¿ç”¨ï¼‰
TERM_MAPPING = {
    # å£è¯­ â†’ ä¸“ä¸šæœ¯è¯­
    "å¸®æˆ‘": "è¯·",
    "é‚£ä¸ª": "",
    "å˜›": "",
    "å§": "",
    "è¿™äº›": "",
    "é‚£å¥—": "ç­‰å·¥å…·",
    # æŠ€æœ¯æœ¯è¯­æ ‡å‡†åŒ–
    "RAG": "æ£€ç´¢å¢å¼ºç”Ÿæˆ",
    "LLM": "å¤§å‹è¯­è¨€æ¨¡å‹",
    "chain": "å¤„ç†é“¾",
    "K8s": "Kubernetes",
    "ELK": "ELKæ—¥å¿—ç³»ç»Ÿ",
    "QPS": "æ¯ç§’æŸ¥è¯¢ç‡(QPS)",
    "top-3": "å‰3ä¸ªç»“æœ",
    "top-5": "å‰5ä¸ªç»“æœ",
    "å‘é‡ç´¢å¼•": "å‘é‡ç´¢å¼•(VI)",
    "çŸ¥è¯†å›¾è°±": "çŸ¥è¯†å›¾è°±(KG)",
    "ç¼“å­˜å‘½ä¸­ç‡": "ç¼“å­˜å‘½ä¸­ç‡(CRH)",
}


# æ­§ä¹‰è¯é»‘åå•ï¼ˆä¼šè§¦å‘è­¦å‘Šä½†ä¸é˜»æ–­ï¼‰
AMBIGUITY_BLACKLIST = ["è¿™ä¸ª", "é‚£ä¸ª", "å®ƒ", "ä»–ä»¬", "æŸäº›"]


# ============================================================================
# å¢å¼ºçš„å®ä½“æŠ½å–å™¨ï¼ˆæ¨¡æ‹ŸçœŸå® LLMï¼‰
# ============================================================================

class PipelineMockExtractor:
    """æµæ°´çº¿ä¸“ç”¨çš„æ¨¡æ‹ŸæŠ½å–å™¨"""
    
    def extract(self, text: str) -> list:
        """ä»æ ‡å‡†åŒ–åçš„æ–‡æœ¬ä¸­æŠ½å–å®ä½“"""
        entities = []
        
        # ===== Integer ç±»å‹ =====
        # æ•°é‡æ¨¡å¼
        int_patterns = [
            (r'(\d+)\s*ç§', 'mode_count'),
            (r'(\d+)\s*ä¸ªäºº', 'team_size'),
            (r'(\d+)\s*ä¸ª', 'count'),
            (r'(\d+)\s*å‘¨', 'duration_weeks'),
            (r'(\d+)\s*ä¸‡', 'budget_wan'),
            (r'(\d+)\s*è½®', 'context_rounds'),
            (r'(\d+)\s*ç§’', 'response_time_sec'),
            (r'çº¦?\s*(\d+)\s*ä¸ªæœåŠ¡', 'service_count'),
        ]
        
        for pattern, name in int_patterns:
            for match in re.finditer(pattern, text):
                full_match = match.group(0)
                entities.append({
                    "name": f"{name}_{len(entities)}",
                    "original_text": full_match,
                    "start_index": match.start(),
                    "end_index": match.end(),
                    "type": "Integer",
                    "value": full_match
                })
        
        # ===== String ç±»å‹ï¼šæŠ€æœ¯æœ¯è¯­ =====
        tech_terms = [
            ("æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)", "technology"),
            ("åŸºäºAPIå°è£…çš„åº”ç”¨", "app_type"),
            ("å¤§å‹è¯­è¨€æ¨¡å‹(LLM)", "model_type"),
            ("å¤„ç†é“¾(Chain)", "component"),
            ("LangChain", "framework"),
            ("Milvus", "database"),
            ("FastAPI", "framework"),
            ("Kubernetes", "platform"),
            ("ELKæ—¥å¿—ç³»ç»Ÿ(Elasticsearch+Logstash+Kibana)", "monitoring"),
            ("Prometheus", "monitoring"),
            ("å¾®æœåŠ¡æ¶æ„", "architecture"),
            ("å¤šè½®å¯¹è¯", "feature"),
        ]
        
        for term, category in tech_terms:
            if term in text:
                idx = text.find(term)
                entities.append({
                    "name": f"{category}_{len(entities)}",
                    "original_text": term,
                    "start_index": idx,
                    "end_index": idx + len(term),
                    "type": "String",
                    "value": term
                })
        
        # ===== List ç±»å‹ =====
        # æŠ€æœ¯æ ˆåˆ—è¡¨
        tech_stack_match = re.search(r'æŠ€æœ¯æ ˆ[^ï¼Œã€‚]*[ï¼š:]\s*([^ã€‚]+(?:[ã€,ï¼Œ][^ã€‚]+)+)', text)
        if tech_stack_match:
            entities.append({
                "name": "tech_stack",
                "original_text": tech_stack_match.group(1).strip('ã€‚'),
                "start_index": tech_stack_match.start(1),
                "end_index": tech_stack_match.end(1),
                "type": "List",
                "value": tech_stack_match.group(1).strip('ã€‚')
            })
        
        # ===== Boolean ç±»å‹ =====
        bool_patterns = [
            (r'(éœ€è¦|ä¸éœ€è¦)æ”¯æŒ', 'support_required'),
            (r'(è¦|ä¸è¦)æ”¯æŒ', 'support_required'),
        ]
        for pattern, name in bool_patterns:
            match = re.search(pattern, text)
            if match:
                entities.append({
                    "name": f"{name}_{len(entities)}",
                    "original_text": match.group(0),
                    "start_index": match.start(),
                    "end_index": match.end(),
                    "type": "Boolean",
                    "value": match.group(1)
                })
        
        # ===== è¯­è¨€æ”¯æŒ =====
        lang_match = re.search(r'(ä¸­è‹±æ–‡åŒè¯­|ä¸­æ–‡|è‹±æ–‡)', text)
        if lang_match:
            entities.append({
                "name": "language_support",
                "original_text": lang_match.group(0),
                "start_index": lang_match.start(),
                "end_index": lang_match.end(),
                "type": "String",
                "value": lang_match.group(0)
            })
        
        # ===== æ·»åŠ å¹»è§‰æµ‹è¯• =====
        entities.append({
            "name": "hallucination",
            "original_text": "è¿™æ˜¯è™šæ„çš„å†…å®¹ä¸å­˜åœ¨äºåŸæ–‡",
            "start_index": 9999,
            "end_index": 10010,
            "type": "String",
            "value": "å¹»è§‰"
        })
        
        return entities


# ============================================================================
# å®Œæ•´æµæ°´çº¿æ¼”ç¤º
# ============================================================================

def load_input_from_file(file_path: str) -> str:
    """ä»æ–‡ä»¶è¯»å–è¾“å…¥å†…å®¹"""
    if not os.path.exists(file_path):
        error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None

    if not file_path.endswith('.txt'):
        warning(f"âš ï¸  è­¦å‘Š: æ–‡ä»¶æ‰©å±•åä¸æ˜¯ .txt: {file_path}")

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        info(f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶: {file_path}")
        info(f"ğŸ“„ æ–‡ä»¶å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        return content.strip()
    except Exception as e:
        error(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return None


def run_full_pipeline(input_text: str = None):
    """æ‰§è¡Œå®Œæ•´æµæ°´çº¿

    Args:
        input_text: å¯é€‰çš„ç”¨æˆ·è¾“å…¥æ–‡æœ¬ã€‚å¦‚æœä¸æä¾›ï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„ RAW_INPUT
    """
    # ç¡®å®šä½¿ç”¨çš„è¾“å…¥æ–‡æœ¬
    if input_text is None:
        input_text = RAW_INPUT
        info("\n" + "=" * 80)
        info("ä½¿ç”¨é»˜è®¤è¾“å…¥ï¼ˆå¯æŒ‡å®šæ–‡ä»¶è·¯å¾„: python3 demo_full_pipeline.py <æ–‡ä»¶è·¯å¾„>ï¼‰")
        info("=" * 80)
    else:
        info("\n" + "=" * 80)
        info("ä½¿ç”¨ä»æ–‡ä»¶è¯»å–çš„è¾“å…¥")
        info("=" * 80)

    info("\n" + "â–ˆ" * 80)
    info("â–ˆ" + " " * 30 + "å®Œæ•´æµæ°´çº¿æ¼”ç¤º" + " " * 32 + "â–ˆ")
    info("â–ˆ" + " " * 20 + "é¢„å¤„ç†æ¨¡å— + ç»“æ„åŒ–æ¨¡å— ååŒå·¥ä½œ" + " " * 18 + "â–ˆ")
    info("â–ˆ" * 80)

    # =========================================================================
    # é˜¶æ®µ 0: å±•ç¤ºåŸå§‹è¾“å…¥
    # =========================================================================
    info("\n" + "=" * 80)
    info("ã€é˜¶æ®µ 0: åŸå§‹ç”¨æˆ·è¾“å…¥ã€‘")
    info("=" * 80)
    info("\n" + input_text)
    
    info("\nğŸ“ è¾“å…¥ç‰¹ç‚¹åˆ†æ:")
    info("  â€¢ åŒ…å«å£è¯­åŒ–è¡¨è¾¾: 'é‚£ä¸ª'ã€'å§'ã€'å˜›'ã€'æ'ã€'å¼„'")
    info("  â€¢ åŒ…å«éæ ‡å‡†æœ¯è¯­: 'å¥—å£³'ã€'å¤§æ¨¡å‹'ã€'K8s'ã€'ELK'")
    info("  â€¢ åŒ…å«å¤šç§æ•°æ®ç±»å‹: æ•°å­—ã€åˆ—è¡¨ã€å¸ƒå°”å€¼")
    info("  â€¢ æ–‡æœ¬ç»“æ„æ¾æ•£ï¼Œéœ€è¦æ ‡å‡†åŒ–")
    info(f"  â€¢ è¾“å…¥æ¥æº: {'æ–‡ä»¶' if input_text != RAW_INPUT else 'é»˜è®¤ç¡¬ç¼–ç '}")
    
    # =========================================================================
    # é˜¶æ®µ 1: Prompt 1.0 é¢„å¤„ç†
    # =========================================================================
    info("\n\n" + "=" * 80)
    info("ã€é˜¶æ®µ 1: Prompt 1.0 é¢„å¤„ç† (prompt_preprocessor)ã€‘")
    info("=" * 80)
    
    info("\nğŸ“‹ æœ¯è¯­æ˜ å°„è¡¨:")
    for old, new in list(TERM_MAPPING.items())[:8]:
        if new:
            info(f"    '{old}' â†’ '{new}'")
        else:
            info(f"    '{old}' â†’ (åˆ é™¤)")
    info("    ... (å…± {} æ¡æ˜ å°„)".format(len(TERM_MAPPING)))
    
    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = PromptPreprocessor(
        mode=ProcessingMode.DICTIONARY,
        term_mapping=TERM_MAPPING,
        ambiguity_blacklist=AMBIGUITY_BLACKLIST,
        use_mock_llm=USE_MOCK,  # æ ¹æ®é…ç½®é€‰æ‹©æ¨¡æ‹Ÿæˆ–çœŸå®LLM
        enable_deep_check=False  # å…³é—­æ·±åº¦æ£€æµ‹ä»¥ä¾¿æ¼”ç¤ºç»§ç»­
    )
    
    info("\n>>> å¼€å§‹é¢„å¤„ç†...")
    start_time = time.time()
    
    # æ‰§è¡Œé¢„å¤„ç†
    prompt10_result = preprocessor.process(
        input_text,
        save_history=True,  # ä¿å­˜å†å²è®°å½•
        show_comparison=False
    )
    
    preprocessing_time = int((time.time() - start_time) * 1000)
    
    # å±•ç¤ºé¢„å¤„ç†ç»“æœ
    info("\n" + "â”€" * 80)
    info("ã€Prompt 1.0 å¤„ç†ç»“æœã€‘")
    info("â”€" * 80)
    
    info(f"\nâœ… å¤„ç†çŠ¶æ€: {prompt10_result.status}")
    info(f"â±ï¸  å¤„ç†è€—æ—¶: {preprocessing_time}ms")
    
    # å±•ç¤ºæœ¯è¯­æ›¿æ¢
    if prompt10_result.terminology_changes:
        info("\nğŸ“ æœ¯è¯­æ›¿æ¢è®°å½•:")
        for old, new in prompt10_result.terminology_changes.items():
            info(f"    '{old}' â†’ '{new}'")
    
    # å±•ç¤ºå¤„ç†æ­¥éª¤
    if prompt10_result.steps:
        info("\nğŸ“Š å¤„ç†æ­¥éª¤:")
        for step in prompt10_result.steps:
            info(f"    {step.step_index}. {step.step_name} ({step.duration_ms}ms)")
    
    info("\nğŸ“„ æ ‡å‡†åŒ–åçš„æ–‡æœ¬:")
    info("â”€" * 60)
    processed_text = prompt10_result.processed_text
    info(processed_text)
    info("â”€" * 60)
    
    # å¯¹æ¯”å±•ç¤º
    info("\nğŸ” å…³é”®å˜åŒ–å¯¹æ¯”:")
    comparisons = [
        ("é‚£ä¸ªï¼Œå¸®æˆ‘æä¸€ä¸ªRAGçš„å¥—å£³åº”ç”¨å§", "å¸®æˆ‘å¼€å‘ä¸€ä¸ªæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)çš„åŸºäºAPIå°è£…çš„åº”ç”¨"),
        ("å¤§æ¨¡å‹åšåº•åº§", "å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åšåº•åº§"),
        ("chainçš„è¯å¤æ‚ä¸€ç‚¹", "å¤„ç†é“¾(Chain)çš„è¯å¤æ‚ä¸€ç‚¹"),
        ("K8sé›†ç¾¤", "Kubernetesé›†ç¾¤"),
        ("ELKé‚£å¥—", "ELKæ—¥å¿—ç³»ç»Ÿ(Elasticsearch+Logstash+Kibana)é‚£å¥—"),
    ]
    for old_phrase, expected_new in comparisons:
        if old_phrase in input_text:
            info(f"    åŸ: {old_phrase}")
            info(f"    æ–°: {expected_new}")
            info("")
    
    # =========================================================================
    # é˜¶æ®µ 2: Prompt 2.0 ç»“æ„åŒ–
    # =========================================================================
    info("\n\n" + "=" * 80)
    info("ã€é˜¶æ®µ 2: Prompt 2.0 ç»“æ„åŒ– (prompt_structurizer)ã€‘")
    info("=" * 80)
    
    info("\n>>> è¾“å…¥: Prompt 1.0 å¤„ç†åçš„æ ‡å‡†åŒ–æ–‡æœ¬")
    
    # ä½¿ç”¨ PromptStructurizer è¿›è¡Œå®Œæ•´å¤„ç†ï¼ˆåŒ…æ‹¬ extraction_logï¼‰
    structurizer = PromptStructurizer(use_mock=USE_MOCK)
    prompt_structure = structurizer.process(processed_text)
    
    # ä»ç»“æœä¸­æå–æ•°æ®
    template = prompt_structure.template_text
    variable_registry = prompt_structure.variable_registry
    extraction_log = prompt_structure.extraction_log
    
    # å°† variable_registry (List[Dict]) è½¬æ¢ä¸º variable_metas (List[VariableMeta])
    variable_metas = []
    for var_dict in variable_registry:
        var_meta = VariableMeta(
            name=var_dict.get('variable', ''),
            original_text=var_dict.get('original_text', ''),
            value=var_dict.get('value', ''),
            data_type=var_dict.get('type', ''),
            start_index=0,  # PromptStructure ä¸­æ²¡æœ‰è¿™ä¸ªä¿¡æ¯ï¼Œè®¾ä¸º0
            end_index=0
        )
        variable_metas.append(var_meta)
    
    info(f"\nâœ… ç»“æ„åŒ–å®Œæˆï¼Œæå–åˆ° {len(variable_metas)} ä¸ªå˜é‡")
    info(f"ğŸ“ æå–æ—¥å¿—è®°å½•æ•°: {len(extraction_log)} æ¡")
    
    # æ˜¾ç¤ºæå–æ—¥å¿—çš„å‰å‡ æ¡
    if extraction_log:
        info(f"\nğŸ“‹ æå–æ—¥å¿— (å‰10æ¡):")
        for log in extraction_log[:10]:
            info(f"  â€¢ {log}")
        if len(extraction_log) > 10:
            info(f"  ... è¿˜æœ‰ {len(extraction_log) - 10} æ¡æ—¥å¿—")
    
    # ç”Ÿæˆçš„æ¨¡æ¿ (Prompt 2.0)
    info("\nğŸ“ ç”Ÿæˆçš„æ¨¡æ¿ (Prompt 2.0):")
    info("â”€" * 60)
    for line in template.split('\n'):
        info(line)
    info("â”€" * 60)
    
    # =========================================================================
    # æœ€ç»ˆè¾“å‡º: å˜é‡æ³¨å†Œè¡¨
    # =========================================================================
    info("\n\n" + "=" * 80)
    info("ã€æœ€ç»ˆè¾“å‡º: å˜é‡æ³¨å†Œè¡¨ (Variable Registry)ã€‘")
    info("=" * 80)
    
    info(json.dumps(variable_registry, indent=2, ensure_ascii=False))
    
    # =========================================================================
    # é˜¶æ®µ3: Prompt 3.0 DSL ç¼–è¯‘å‡†å¤‡
    # =========================================================================
    info("\n>>> å‡†å¤‡ Prompt 2.0 ç»“æœç”¨äº DSL ç¼–è¯‘...")
    
    # åˆ›å»º Prompt20Result å¯¹è±¡
    prompt20_result = create_prompt20_result(
        source_prompt10_id=prompt10_result.id,
        original_text=processed_text,
        template_text=template,
        variables=variable_metas,
        processing_time_ms=0
    )
    
    # è½¬æ¢ä¸º DSL ç¼–è¯‘å™¨è¾“å…¥æ ¼å¼
    dsl_input = convert_prompt20_to_dsl_input(prompt20_result)
    info(f"âœ… Prompt 2.0 ç»“æœå·²å‡†å¤‡ï¼ŒåŒ…å« {len(prompt20_result.variables)} ä¸ªå˜é‡")
    
    # =========================================================================
    # éªŒè¯: æ¨¡æ¿å›å¡«è¿˜åŸ
    # =========================================================================
    info("\n\n" + "=" * 80)
    info("ã€éªŒè¯: æ¨¡æ¿å›å¡«è¿˜åŸã€‘")
    info("=" * 80)
    
    filled = template
    for var in variable_metas:
        placeholder = f"{{{{{var.name}}}}}"
        filled = filled.replace(placeholder, var.original_text)
    
    is_match = filled == processed_text
    info(f"\nè¿˜åŸåä¸ Prompt 1.0 ä¸€è‡´: {'âœ… æ˜¯' if is_match else 'âŒ å¦'}")

    # =========================================================================
    # é˜¶æ®µ3: Prompt 3.0 DSL ç¼–è¯‘
    # =========================================================================
    info("\n\n" + "=" * 80)
    info("ã€é˜¶æ®µ 3: Prompt 3.0 DSL ç¼–è¯‘ (prompt_dslcompiler)ã€‘")
    info("=" * 80)

    info("\n>>> å¼€å§‹ DSL ç¼–è¯‘...")
    start_time = time.time()

    # åˆ›å»ºè‡ªæˆ‘ä¿®æ­£å¾ªç¯ç¼–è¯‘å™¨ï¼ˆç­–ç•¥ Dï¼‰
    compiler = SelfCorrectionLoop(max_retries=3, use_mock=USE_MOCK, auto_fix_threshold=3)
    success, dsl_code, validation_result, compile_history = compiler.compile_with_retry(dsl_input)

    dsl_compile_time = int((time.time() - start_time) * 1000)

    # æ£€æŸ¥ç¼–è¯‘çŠ¶æ€
    compile_decision = compile_history.get('final_decision', 'unknown')

    if success or compile_decision == 'partial_auto_fixed':
        if compile_decision == 'partial_auto_fixed':
            warning(f"\nâš ï¸  DSL éƒ¨åˆ†ä¿®å¤æˆåŠŸï¼ˆè‡ªåŠ¨ä¿®å¤åä»æœ‰å°‘é‡é”™è¯¯ï¼‰ï¼è€—æ—¶: {dsl_compile_time}ms")
        else:
            info(f"\nâœ… DSL ç¼–è¯‘æˆåŠŸï¼è€—æ—¶: {dsl_compile_time}ms")
        info("\nğŸ“„ ç”Ÿæˆçš„ DSL ä»£ç :")
        info("â”€" * 60)
        for line in dsl_code.split('\n'):
            info(line)
        info("â”€" * 60)

        info("\nğŸ“Š éªŒè¯ç»“æœ:")
        info(validation_result.get_report())

        # å¦‚æœæ˜¯éƒ¨åˆ†ä¿®å¤çŠ¶æ€ï¼Œæ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
        if compile_decision == 'partial_auto_fixed':
            warning("\nâš ï¸  æ³¨æ„ï¼šDSL ä»£ç ä»æœ‰å°‘é‡éªŒè¯é”™è¯¯ï¼Œä½†å·²å°è¯•è¿›å…¥ä»£ç ç”Ÿæˆé˜¶æ®µ")
            if validation_result.errors:
                info("å‰©ä½™é”™è¯¯:")
                for err in validation_result.errors:
                    error(f"  {err}")

        # =========================================================================
        # é˜¶æ®µ 4: Prompt 4.0 ä»£ç ç”Ÿæˆ
        # =========================================================================
        info("\n\n" + "=" * 80)
        info("ã€é˜¶æ®µ 4: Prompt 4.0 ä»£ç ç”Ÿæˆ (prompt_codegenetate)ã€‘")
        info("=" * 80)

        info("\n>>> å¼€å§‹ä»£ç ç”Ÿæˆ...")
        start_time_codegen = time.time()

        # åˆ›å»ºä»£ç ç¼–è¯‘å™¨
        code_compiler = WaActCompiler()
        try:
            modules, main_code, compile_details = code_compiler.compile(
                dsl_code,
                clustering_strategy="hybrid",
                visualize=False
            )

            codegen_time = int((time.time() - start_time_codegen) * 1000)
            info(f"\nâœ… ä»£ç ç”ŸæˆæˆåŠŸï¼è€—æ—¶: {codegen_time}ms")

            # æ˜¾ç¤ºç”Ÿæˆçš„æ¨¡å—
            info("\nğŸ“¦ ç”Ÿæˆçš„æ¨¡å—:")
            for i, module in enumerate(modules, 1):
                info(f"  {i}. {module.name} ({'async' if module.is_async else 'sync'})")

            # æ˜¾ç¤ºä¸»å·¥ä½œæµä»£ç 
            info("\nğŸ“„ ä¸»å·¥ä½œæµä»£ç :")
            info("â”€" * 60)
            for line in main_code.split('\n'):
                info(line)
            info("â”€" * 60)

            # å¯¼å‡ºåˆ°æ–‡ä»¶
            output_file = "generated_workflow.py"
            code_compiler.export_to_file(modules, main_code, output_file)
            info(f"\nğŸ’¾ ä»£ç å·²å¯¼å‡ºåˆ°: {output_file}")
        except Exception as e:
            error(f"\nâŒ ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            warning("DSL ä»£ç å­˜åœ¨ä¸¥é‡é”™è¯¯ï¼Œæ— æ³•ç”Ÿæˆå¯æ‰§è¡Œä»£ç ")
            modules = []
            main_code = ""
            compile_details = {
                'step1_parsing': {'status': 'failed', 'reason': str(e)},
                'step2_dependency': {'status': 'skipped', 'reason': 'Parsing failed'},
                'step3_clustering': {'status': 'skipped', 'reason': 'Parsing failed'},
                'step4_generation': {'status': 'skipped', 'reason': 'Parsing failed'},
                'step5_orchestration': {'status': 'skipped', 'reason': 'Parsing failed'}
            }
            codegen_time = int((time.time() - start_time_codegen) * 1000)
    else:
        warning(f"\nâš ï¸  DSL ç¼–è¯‘å¤±è´¥ï¼è€—æ—¶: {dsl_compile_time}ms")
        info("\nğŸ“„ ç”Ÿæˆçš„ DSL ä»£ç  (æœ‰é”™è¯¯):")
        info("â”€" * 60)
        for line in dsl_code.split('\n'):
            info(line)
        info("â”€" * 60)

        info("\nâŒ éªŒè¯é”™è¯¯:")
        for err in validation_result.errors[:5]:
            error(f"  {err}")

        # DSL ç¼–è¯‘å¤±è´¥æ—¶ï¼Œè·³è¿‡ä»£ç ç”Ÿæˆé˜¶æ®µï¼Œä½†ä¿ç•™ç©ºæ•°æ®
        info("\n>>> DSL ç¼–è¯‘å¤±è´¥ï¼Œè·³è¿‡ä»£ç ç”Ÿæˆé˜¶æ®µ")
        modules = []
        main_code = ""
        compile_details = {
            'step1_parsing': {'status': 'skipped', 'reason': 'DSL compilation failed'},
            'step2_dependency': {'status': 'skipped', 'reason': 'DSL compilation failed'},
            'step3_clustering': {'status': 'skipped', 'reason': 'DSL compilation failed'},
            'step4_generation': {'status': 'skipped', 'reason': 'DSL compilation failed'},
            'step5_orchestration': {'status': 'skipped', 'reason': 'DSL compilation failed'}
        }
        codegen_time = 0

    # =========================================================================
    # æ€»ç»“
    # =========================================================================
    info("\n\n" + "â–ˆ" * 80)
    info("â–ˆ" + " " * 32 + "æµæ°´çº¿æ€»ç»“" + " " * 34 + "â–ˆ")
    info("â–ˆ" * 80)
    
    info(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š å¤„ç†ç»Ÿè®¡                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ åŸå§‹è¾“å…¥é•¿åº¦: {len(input_text):4} å­—ç¬¦                                              â”‚
â”‚ æ ‡å‡†åŒ–åé•¿åº¦: {len(processed_text):4} å­—ç¬¦                                              â”‚
â”‚ æœ¯è¯­æ›¿æ¢æ•°é‡: {len(prompt10_result.terminology_changes):4} å¤„                                              â”‚
â”‚ è¯†åˆ«å˜é‡æ•°é‡: {len(variable_metas):4} ä¸ª                                              â”‚
â”‚ å˜é‡ç±»å‹åˆ†å¸ƒ:                                                                â”‚
â”‚   - Integer: {len([v for v in variable_metas if v.data_type == 'Integer']):2} ä¸ª                                                        â”‚
â”‚   - String:  {len([v for v in variable_metas if v.data_type == 'String']):2} ä¸ª                                                        â”‚
â”‚   - List:    {len([v for v in variable_metas if v.data_type == 'List']):2} ä¸ª                                                        â”‚
â”‚   - Boolean: {len([v for v in variable_metas if v.data_type == 'Boolean']):2} ä¸ª                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¯ é¢„å¤„ç†æ¨¡å—è´¡çŒ® (Prompt 1.0 é¢„å¤„ç†)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ å£è¯­åŒ–è¡¨è¾¾æ¶ˆé™¤: 'é‚£ä¸ª'ã€'å§'ã€'å˜›'ã€'æ' â†’ è§„èŒƒä¹¦é¢è¯­                     â”‚
â”‚ â€¢ æœ¯è¯­æ ‡å‡†åŒ–: 'å¥—å£³'â†’'åŸºäºAPIå°è£…çš„åº”ç”¨', 'K8s'â†’'Kubernetes'                â”‚
â”‚ â€¢ è¯­æ³•ä¿®æ­£: ä½¿æ–‡æœ¬ç»“æ„æ›´æ¸…æ™°è§„èŒƒ                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¯ ç»“æ„åŒ–æ¨¡å—è´¡çŒ® (Prompt 2.0 ç»“æ„åŒ–)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ å®ä½“æŠ½å–: ä»æ ‡å‡†åŒ–æ–‡æœ¬ä¸­è¯†åˆ«æ‰€æœ‰å¯å‚æ•°åŒ–çš„å˜é‡                            â”‚
â”‚ â€¢ å¹»è§‰é˜²å¾¡: æ‹’ç» LLM è™šæ„çš„ä¸å­˜åœ¨å®ä½“                                        â”‚
â”‚ â€¢ ç±»å‹æ¸…æ´—: '8å‘¨'â†’8(Integer), 'éœ€è¦æ”¯æŒ'â†’True(Boolean)                      â”‚
â”‚ â€¢ æ¨¡æ¿ç”Ÿæˆ: ç”Ÿæˆå¯å¤ç”¨çš„å‚æ•°åŒ–æ¨¡æ¿                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")
    
    info("â–ˆ" * 80)
    info("â–ˆ" + " " * 32 + "æ¼”ç¤ºå®Œæˆ" + " " * 36 + "â–ˆ")
    info("â–ˆ" * 80)
    
    # =========================================================================
    # ä¿å­˜å®Œæ•´æµæ°´çº¿å†å²è®°å½•
    # =========================================================================
    info("\n>>> ä¿å­˜æµæ°´çº¿å†å²è®°å½•...")
    
    # ç»Ÿè®¡å˜é‡ç±»å‹
    type_stats = {}
    for var in variable_metas:
        dtype = var.data_type
        type_stats[dtype] = type_stats.get(dtype, 0) + 1
    
    # å‡†å¤‡ç¬¬å››é˜¶æ®µæ•°æ®
    prompt40_modules_dict = []
    prompt40_module_count = 0
    prompt40_main_code = ""
    prompt40_time_ms = 0
    prompt40_step1_parsing = {}
    prompt40_step2_dependency = {}
    prompt40_step3_clustering = {}
    prompt40_step4_generation = {}
    prompt40_step5_orchestration = {}
    prompt40_module_bodies = {}  # æ·»åŠ æ¨¡å—å‡½æ•°ä½“ä»£ç å­—å…¸

    if success:
        # è½¬æ¢ ModuleDefinition å¯¹è±¡ä¸ºå­—å…¸ï¼Œæ’é™¤ä¸å¯åºåˆ—åŒ–çš„å­—æ®µ
        for module in modules:
            module_dict = {
                'name': module.name,
                'inputs': module.inputs,
                'outputs': module.outputs,
                'is_async': module.is_async,
                'body_code': module.body_code,  # æ·»åŠ å‡½æ•°ä½“ä»£ç 
                'code_lines_count': len(module.body_code.split('\n')) if module.body_code else 0,
            }
            prompt40_modules_dict.append(module_dict)
            prompt40_module_bodies[module.name] = module.body_code  # ä¿å­˜åˆ°å­—å…¸
        prompt40_module_count = len(modules)
        prompt40_main_code = main_code
        prompt40_time_ms = codegen_time

        # ä¿å­˜ç¼–è¯‘æ­¥éª¤è¯¦æƒ…
        prompt40_step1_parsing = compile_details.get('step1_parsing', {})
        prompt40_step2_dependency = compile_details.get('step2_dependency', {})
        prompt40_step3_clustering = compile_details.get('step3_clustering', {})
        prompt40_step4_generation = compile_details.get('step4_generation', {})
        prompt40_step5_orchestration = compile_details.get('step5_orchestration', {})

    # åˆ›å»ºæµæ°´çº¿å†å²è®°å½•
    pipeline_history = PipelineHistory(
        pipeline_id=generate_id(),
        timestamp=get_timestamp(),
        raw_input=input_text,

        # é˜¶æ®µ1ç»“æœ
        prompt10_id=prompt10_result.id,
        prompt10_original=prompt10_result.original_text,
        prompt10_processed=prompt10_result.processed_text,
        prompt10_mode=prompt10_result.mode,
        prompt10_steps=[s.to_dict() for s in prompt10_result.steps],
        prompt10_terminology_changes=prompt10_result.terminology_changes,
        prompt10_ambiguity_detected=prompt10_result.ambiguity_detected,
        prompt10_status=prompt10_result.status,
        prompt10_time_ms=prompt10_result.processing_time_ms,

        # é˜¶æ®µ2ç»“æœ
        prompt20_id=generate_id(),
        prompt20_template=template,
        prompt20_variables=variable_registry,
        prompt20_variable_count=len(variable_metas),
        prompt20_type_stats=type_stats,
        prompt20_extraction_log=extraction_log,
        prompt20_time_ms=0,

        # é˜¶æ®µ3ç»“æœ (DSLç¼–è¯‘) - æ— è®ºæˆåŠŸå¤±è´¥éƒ½è®°å½• DSL ä»£ç å’ŒéªŒè¯ç»“æœ
        prompt30_id=generate_id(),
        prompt30_dsl_code=dsl_code,  # æ€»æ˜¯è®°å½• DSL ä»£ç 
        prompt30_validation_result=validation_result.to_dict(),  # æ€»æ˜¯è®°å½•éªŒè¯ç»“æœ
        prompt30_time_ms=dsl_compile_time,
        prompt30_compile_history=compile_history,  # æ–°å¢ï¼šç¼–è¯‘å†å²ï¼ˆç­–ç•¥ Dï¼‰
        prompt30_success=success,  # æ–°å¢ï¼šç¼–è¯‘æˆåŠŸæ ‡å¿—

        # é˜¶æ®µ4ç»“æœ (ä»£ç ç”Ÿæˆ)
        prompt40_id=generate_id(),
        prompt40_modules=prompt40_modules_dict,
        prompt40_module_count=prompt40_module_count,
        prompt40_main_code=prompt40_main_code,
        prompt40_time_ms=codegen_time,
        prompt40_module_bodies=prompt40_module_bodies,  # æ·»åŠ æ¨¡å—å‡½æ•°ä½“å­—å…¸

        # é˜¶æ®µ4å­æ­¥éª¤è¯¦æƒ…
        prompt40_step1_parsing=prompt40_step1_parsing,
        prompt40_step2_dependency=prompt40_step2_dependency,
        prompt40_step3_clustering=prompt40_step3_clustering,
        prompt40_step4_generation=prompt40_step4_generation,
        prompt40_step5_orchestration=prompt40_step5_orchestration,

        # æ•´ä½“çŠ¶æ€ - æ ¹æ®ç¼–è¯‘å†³ç­–åˆ¤æ–­
        total_time_ms=prompt10_result.processing_time_ms + dsl_compile_time + prompt40_time_ms,
        error_message=None
    )

    # æ ¹æ®ç¼–è¯‘å†³ç­–æ›´æ–°æ•´ä½“çŠ¶æ€
    if compile_decision == 'success':
        pipeline_history.overall_status = "success"
    elif compile_decision == 'partial_auto_fixed':
        pipeline_history.overall_status = "partial"  # DSLæœ‰è¯¯ä½†èƒ½ç”Ÿæˆä»£ç 
    else:
        pipeline_history.overall_status = "partial"  # DSLå¤±è´¥
    
    # ä¿å­˜å†å²è®°å½•
    history_manager = HistoryManager()
    history_manager.save_pipeline_history(pipeline_history)
    
    info(f"âœ… æµæ°´çº¿å†å²å·²ä¿å­˜: {pipeline_history.pipeline_id}")
    info(f"ğŸ“ æŸ¥çœ‹å†å²: python3 view_history.py pipeline")
    info(f"ğŸ“„ å¯¼å‡ºæŠ¥å‘Š: python3 view_history.py export-pipeline")


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        file_path = sys.argv[1]
        info(f"ğŸ“‚ å°è¯•ä»æ–‡ä»¶è¯»å–è¾“å…¥: {file_path}")

        # å°è¯•ä»æ–‡ä»¶è¯»å–
        content = load_input_from_file(file_path)

        if content is None:
            error("âŒ æ— æ³•è¯»å–æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤è¾“å…¥")
            run_full_pipeline()
        elif not content.strip():
            error("âŒ æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤è¾“å…¥")
            run_full_pipeline()
        else:
            run_full_pipeline(content)
    else:
        # æ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤è¾“å…¥
        info("ğŸ’¡ æç¤º: ä½¿ç”¨ 'python3 demo_full_pipeline.py <æ–‡ä»¶è·¯å¾„>' ä»æ–‡ä»¶è¯»å–è¾“å…¥")
        run_full_pipeline()
