"""
å®Œæ•´æµæ°´çº¿æ¼”ç¤ºï¼šprompt_preprocessor.py + prompt_structurizer.py ååŒå·¥ä½œ
å±•ç¤ºä»å£è¯­åŒ–è¾“å…¥åˆ°ç»“æ„åŒ–æ¨¡æ¿çš„å®Œæ•´è½¬æ¢è¿‡ç¨‹
"""

import json
import re
import time

# ============================================================================
# å¯¼å…¥é¡¹ç›®æ¨¡å—
# ============================================================================

from logger import info, warning, error
from dataclasses import asdict
from data_models import (
    ProcessingMode, Prompt10Result, StepSnapshot, get_timestamp, generate_id,
    create_prompt20_result, convert_prompt20_to_dsl_input
)

# å¯¼å…¥é¢„å¤„ç†æ¨¡å—ï¼ˆåŸ 1.pyï¼‰
from prompt_preprocessor import PromptPreprocessor

# å¯¼å…¥ç»“æ„åŒ–æ¨¡å—ï¼ˆåŸ 2.pyï¼‰
from prompt_structurizer import (
    PromptStructurizer,
    HallucinationFirewall,
    TypeCleaner,
    EntityConflictResolver,
    VariableMeta,
    LLMEntityExtractor  # çœŸå® LLM å®ä½“æŠ½å–å™¨
)

# å¯¼å…¥ DSL ç¼–è¯‘å™¨æ¨¡å—ï¼ˆåŸ prompt_dslcompiler.pyï¼‰
from prompt_dslcompiler import SelfCorrectionLoop, ValidationResult

# å¯¼å…¥ä»£ç ç”Ÿæˆå™¨æ¨¡å—ï¼ˆåŸ prompt_codegenetate.pyï¼‰
from prompt_codegenetate import WaActCompiler

# å¯¼å…¥å†å²è®°å½•ç®¡ç†
from history_manager import HistoryManager, PipelineHistory


# ============================================================================
# é…ç½®
# ============================================================================
# æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿ LLM å®¢æˆ·ç«¯ï¼ˆè®¾ä¸º True å¯é¿å…çœŸå® API è°ƒç”¨ï¼‰
USE_MOCK = False  # é»˜è®¤ä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯ï¼Œé¿å…æ„å¤– API è°ƒç”¨
# å¦‚æœè¦ä½¿ç”¨çœŸå® LLMï¼Œè¯·è®¾ç½®ä¸º False å¹¶ç¡®ä¿é…ç½®äº†æœ‰æ•ˆçš„ API å¯†é’¥
# USE_MOCK = False

# ============================================================================
# å¤æ‚æµ‹è¯•åœºæ™¯è®¾è®¡
# ============================================================================

# åŸå§‹å£è¯­åŒ–è¾“å…¥ï¼ˆæ•…æ„è®¾è®¡å¾—å¾ˆå£è¯­åŒ–ã€ä¸è§„èŒƒï¼‰
RAW_INPUT = """
å¸®æˆ‘è®¾è®¡ä¸€ä¸ªæ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œéœ€è¦å¤„ç†å¤šé¢†åŸŸçŸ¥è¯†åº“çš„æ£€ç´¢ä¸æ¨ç†ã€‚

é¦–å…ˆï¼Œç”¨æˆ·è¾“å…¥æŸ¥è¯¢åï¼Œç³»ç»Ÿéœ€è¦åˆ¤æ–­æŸ¥è¯¢ç±»å‹ï¼šå¦‚æœæ˜¯ç®€å•äº‹å®æŸ¥è¯¢ï¼Œèµ°å‘é‡æ£€ç´¢é€šé“ï¼›å¦‚æœæ˜¯å¤æ‚æ¨ç†æŸ¥è¯¢ï¼Œå…ˆè¿›è¡Œæ„å›¾åˆ†è§£ï¼Œå†èµ°å›¾æ•°æ®åº“æ£€ç´¢ï¼›å¦‚æœæ˜¯ä»£ç ç›¸å…³é—®é¢˜ï¼Œåˆ™è°ƒç”¨ä»£ç åˆ†æå¼•æ“ã€‚

å‘é‡æ£€ç´¢æ¨¡å¼ä¸‹ï¼Œå¦‚æœç›¸ä¼¼åº¦è¶…è¿‡0.85ï¼Œç›´æ¥è¿”å›top-3ç»“æœï¼›å¦åˆ™ç»“åˆé‡æ’åºæ¨¡å‹é‡æ–°è¯„åˆ†ï¼Œå†è¿”å›top-5ã€‚æ£€ç´¢å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°æ··åˆæ£€ç´¢æ¨¡å¼ã€‚

å›¾æ•°æ®åº“æ£€ç´¢æ—¶ï¼Œéœ€è¦æ²¿ç€çŸ¥è¯†å›¾è°±è¿›è¡Œ2è·³é‚»å±…æ¢ç´¢ï¼Œå¦‚æœæ‰¾åˆ°åŒ¹é…èŠ‚ç‚¹åˆ™è¿”å›ç›¸å…³å®ä½“å’Œå…³ç³»ï¼Œå¦åˆ™å›é€€åˆ°å…¨é‡æœç´¢ã€‚æ¯æ¬¡æŸ¥è¯¢éƒ½è¦ç¼“å­˜ç»“æœï¼Œç¼“å­˜æœ‰æ•ˆæœŸ30åˆ†é’Ÿã€‚

ä»£ç åˆ†æå¼•æ“æ”¯æŒPythonå’ŒJavaä»£ç ï¼Œå¦‚æœä»£ç è¡Œæ•°è¶…è¿‡500è¡Œï¼Œåªè¿›è¡Œé™æ€åˆ†æï¼›å¦‚æœå°‘äº500è¡Œï¼Œåˆ™è¿›è¡Œå®Œæ•´è¯­ä¹‰åˆ†æå¹¶ç”Ÿæˆè§£é‡Šæ–‡æ¡£ã€‚

ç”¨æˆ·åé¦ˆç¯èŠ‚ï¼šå¦‚æœç”¨æˆ·å¯¹ç»“æœä¸æ»¡æ„ï¼Œç‚¹å‡»"é‡æ–°ç”Ÿæˆ"æ—¶å¯ç”¨æ›´å¼ºçš„æ¨ç†æ¨¡å‹ï¼›å¦‚æœè¿ç»­3æ¬¡ä¸æ»¡æ„ï¼Œåˆ™è‡ªåŠ¨å‡çº§åˆ°äººå·¥å®¡æ ¸é˜Ÿåˆ—ã€‚

æ•°æ®æºé…ç½®ï¼šçŸ¥è¯†åº“AåŒ…å«2000ä¸ªåŒ»å­¦æ–‡æ¡£ï¼ŒçŸ¥è¯†åº“BåŒ…å«3000ä¸ªæŠ€æœ¯æ–‡æ¡£ï¼ŒçŸ¥è¯†åº“CåŒ…å«1500ä¸ªæ³•å¾‹æ–‡æ¡£ã€‚æ¯ä¸ªçŸ¥è¯†åº“éƒ½æœ‰ç‹¬ç«‹çš„å‘é‡ç´¢å¼•ï¼Œå‘é‡ç»´åº¦ç»Ÿä¸€ä¸º1536ã€‚

å¹¶å‘æ§åˆ¶ï¼šç³»ç»Ÿæ”¯æŒæœ€å¤§50ä¸ªå¹¶å‘è¯·æ±‚ï¼Œå¦‚æœè¶…è¿‡åˆ™æ’é˜Ÿç­‰å¾…ã€‚æ™®é€šç”¨æˆ·ä¼˜å…ˆçº§è®¾ä¸º1ï¼ŒVIPç”¨æˆ·ä¼˜å…ˆçº§è®¾ä¸º5ï¼Œç®¡ç†å‘˜ä¼˜å…ˆçº§è®¾ä¸º10ã€‚

å®‰å…¨ç­–ç•¥ï¼šæ‰€æœ‰æŸ¥è¯¢å†…å®¹ç»è¿‡æ•æ„Ÿè¯è¿‡æ»¤ï¼Œå¦‚æœæ£€æµ‹åˆ°è¿è§„å†…å®¹åˆ™æ‹’ç»æœåŠ¡å¹¶è®°å½•æ—¥å¿—ã€‚å¯¹äºé‡‘èç±»æŸ¥è¯¢ï¼Œéœ€è¦äºŒæ¬¡ç¡®è®¤ç”¨æˆ·èº«ä»½ã€‚

å“åº”æ—¶é—´è¦æ±‚ï¼šå‘é‡æ£€ç´¢è¦åœ¨500mså†…å®Œæˆï¼Œå›¾æ•°æ®åº“æ£€ç´¢åœ¨1ç§’å†…å®Œæˆï¼Œä»£ç åˆ†æåœ¨2ç§’å†…å®Œæˆã€‚æ€»å“åº”æ—¶é—´ä¸è¶…è¿‡3ç§’ï¼Œå¦åˆ™é™çº§æœåŠ¡ã€‚

æ—¥å¿—çº§åˆ«ï¼šé”™è¯¯æ—¥å¿—ä¿ç•™90å¤©ï¼Œè®¿é—®æ—¥å¿—ä¿ç•™30å¤©ï¼Œè°ƒè¯•æ—¥å¿—ä¿ç•™7å¤©ã€‚æ‰€æœ‰æ—¥å¿—éƒ½è¦ä¸Šä¼ åˆ°ä¸­å¤®æ—¥å¿—ç³»ç»Ÿã€‚

ç›‘æ§æŒ‡æ ‡ï¼šQPSã€å¹³å‡å“åº”æ—¶é—´ã€95åˆ†ä½å“åº”æ—¶é—´ã€ç¼“å­˜å‘½ä¸­ç‡ã€æ£€ç´¢å‡†ç¡®ç‡ã€‚å¦‚æœQPSä½äº10æŒç»­10åˆ†é’Ÿï¼Œè§¦å‘å‘Šè­¦ï¼›å¦‚æœ95åˆ†ä½å“åº”æ—¶é—´è¶…è¿‡3ç§’æŒç»­5åˆ†é’Ÿï¼Œè§¦å‘æ‰©å®¹ã€‚
""".strip()

# æœ¯è¯­æ˜ å°„è¡¨ï¼ˆprompt_preprocessor.py ä½¿ç”¨ï¼‰
TERM_MAPPING = {
    # å£è¯­ â†’ ä¸“ä¸šæœ¯è¯­
    "å¸®æˆ‘": "è¯·",
    "é‚£ä¸ª": "",
    "å˜›": "",
    "å§": "",
    "è¿™äº›": "",
    "é‚£å¥—": "ç­‰å·¥å…·",
    # æŠ€æœ¯æœ¯è¯­æ ‡å‡†åŒ–
    "RAG": "æ£€ç´¢å¢å¼ºç”Ÿæˆ",
    "LLM": "å¤§å‹è¯­è¨€æ¨¡å‹",
    "chain": "å¤„ç†é“¾",
    "K8s": "Kubernetes",
    "ELK": "ELKæ—¥å¿—ç³»ç»Ÿ",
    "QPS": "æ¯ç§’æŸ¥è¯¢ç‡(QPS)",
    "top-3": "å‰3ä¸ªç»“æœ",
    "top-5": "å‰5ä¸ªç»“æœ",
    "å‘é‡ç´¢å¼•": "å‘é‡ç´¢å¼•(VI)",
    "çŸ¥è¯†å›¾è°±": "çŸ¥è¯†å›¾è°±(KG)",
    "ç¼“å­˜å‘½ä¸­ç‡": "ç¼“å­˜å‘½ä¸­ç‡(CRH)",
}


# æ­§ä¹‰è¯é»‘åå•ï¼ˆä¼šè§¦å‘è­¦å‘Šä½†ä¸é˜»æ–­ï¼‰
AMBIGUITY_BLACKLIST = ["è¿™ä¸ª", "é‚£ä¸ª", "å®ƒ", "ä»–ä»¬", "æŸäº›"]


# ============================================================================
# å¢å¼ºçš„å®ä½“æŠ½å–å™¨ï¼ˆæ¨¡æ‹ŸçœŸå® LLMï¼‰
# ============================================================================

class PipelineMockExtractor:
    """æµæ°´çº¿ä¸“ç”¨çš„æ¨¡æ‹ŸæŠ½å–å™¨"""
    
    def extract(self, text: str) -> list:
        """ä»æ ‡å‡†åŒ–åçš„æ–‡æœ¬ä¸­æŠ½å–å®ä½“"""
        entities = []
        
        # ===== Integer ç±»å‹ =====
        # æ•°é‡æ¨¡å¼
        int_patterns = [
            (r'(\d+)\s*ç§', 'mode_count'),
            (r'(\d+)\s*ä¸ªäºº', 'team_size'),
            (r'(\d+)\s*ä¸ª', 'count'),
            (r'(\d+)\s*å‘¨', 'duration_weeks'),
            (r'(\d+)\s*ä¸‡', 'budget_wan'),
            (r'(\d+)\s*è½®', 'context_rounds'),
            (r'(\d+)\s*ç§’', 'response_time_sec'),
            (r'çº¦?\s*(\d+)\s*ä¸ªæœåŠ¡', 'service_count'),
        ]
        
        for pattern, name in int_patterns:
            for match in re.finditer(pattern, text):
                full_match = match.group(0)
                entities.append({
                    "name": f"{name}_{len(entities)}",
                    "original_text": full_match,
                    "start_index": match.start(),
                    "end_index": match.end(),
                    "type": "Integer",
                    "value": full_match
                })
        
        # ===== String ç±»å‹ï¼šæŠ€æœ¯æœ¯è¯­ =====
        tech_terms = [
            ("æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)", "technology"),
            ("åŸºäºAPIå°è£…çš„åº”ç”¨", "app_type"),
            ("å¤§å‹è¯­è¨€æ¨¡å‹(LLM)", "model_type"),
            ("å¤„ç†é“¾(Chain)", "component"),
            ("LangChain", "framework"),
            ("Milvus", "database"),
            ("FastAPI", "framework"),
            ("Kubernetes", "platform"),
            ("ELKæ—¥å¿—ç³»ç»Ÿ(Elasticsearch+Logstash+Kibana)", "monitoring"),
            ("Prometheus", "monitoring"),
            ("å¾®æœåŠ¡æ¶æ„", "architecture"),
            ("å¤šè½®å¯¹è¯", "feature"),
        ]
        
        for term, category in tech_terms:
            if term in text:
                idx = text.find(term)
                entities.append({
                    "name": f"{category}_{len(entities)}",
                    "original_text": term,
                    "start_index": idx,
                    "end_index": idx + len(term),
                    "type": "String",
                    "value": term
                })
        
        # ===== List ç±»å‹ =====
        # æŠ€æœ¯æ ˆåˆ—è¡¨
        tech_stack_match = re.search(r'æŠ€æœ¯æ ˆ[^ï¼Œã€‚]*[ï¼š:]\s*([^ã€‚]+(?:[ã€,ï¼Œ][^ã€‚]+)+)', text)
        if tech_stack_match:
            entities.append({
                "name": "tech_stack",
                "original_text": tech_stack_match.group(1).strip('ã€‚'),
                "start_index": tech_stack_match.start(1),
                "end_index": tech_stack_match.end(1),
                "type": "List",
                "value": tech_stack_match.group(1).strip('ã€‚')
            })
        
        # ===== Boolean ç±»å‹ =====
        bool_patterns = [
            (r'(éœ€è¦|ä¸éœ€è¦)æ”¯æŒ', 'support_required'),
            (r'(è¦|ä¸è¦)æ”¯æŒ', 'support_required'),
        ]
        for pattern, name in bool_patterns:
            match = re.search(pattern, text)
            if match:
                entities.append({
                    "name": f"{name}_{len(entities)}",
                    "original_text": match.group(0),
                    "start_index": match.start(),
                    "end_index": match.end(),
                    "type": "Boolean",
                    "value": match.group(1)
                })
        
        # ===== è¯­è¨€æ”¯æŒ =====
        lang_match = re.search(r'(ä¸­è‹±æ–‡åŒè¯­|ä¸­æ–‡|è‹±æ–‡)', text)
        if lang_match:
            entities.append({
                "name": "language_support",
                "original_text": lang_match.group(0),
                "start_index": lang_match.start(),
                "end_index": lang_match.end(),
                "type": "String",
                "value": lang_match.group(0)
            })
        
        # ===== æ·»åŠ å¹»è§‰æµ‹è¯• =====
        entities.append({
            "name": "hallucination",
            "original_text": "è¿™æ˜¯è™šæ„çš„å†…å®¹ä¸å­˜åœ¨äºåŸæ–‡",
            "start_index": 9999,
            "end_index": 10010,
            "type": "String",
            "value": "å¹»è§‰"
        })
        
        return entities


# ============================================================================
# å®Œæ•´æµæ°´çº¿æ¼”ç¤º
# ============================================================================

def run_full_pipeline():
    """æ‰§è¡Œå®Œæ•´æµæ°´çº¿"""
    
    info("\n" + "â–ˆ" * 80)
    info("â–ˆ" + " " * 30 + "å®Œæ•´æµæ°´çº¿æ¼”ç¤º" + " " * 32 + "â–ˆ")
    info("â–ˆ" + " " * 20 + "é¢„å¤„ç†æ¨¡å— + ç»“æ„åŒ–æ¨¡å— ååŒå·¥ä½œ" + " " * 18 + "â–ˆ")
    info("â–ˆ" * 80)
    
    # =========================================================================
    # é˜¶æ®µ 0: å±•ç¤ºåŸå§‹è¾“å…¥
    # =========================================================================
    info("\n" + "=" * 80)
    info("ã€é˜¶æ®µ 0: åŸå§‹ç”¨æˆ·è¾“å…¥ã€‘")
    info("=" * 80)
    info("\n" + RAW_INPUT)
    
    info("\nğŸ“ è¾“å…¥ç‰¹ç‚¹åˆ†æ:")
    info("  â€¢ åŒ…å«å£è¯­åŒ–è¡¨è¾¾: 'é‚£ä¸ª'ã€'å§'ã€'å˜›'ã€'æ'ã€'å¼„'")
    info("  â€¢ åŒ…å«éæ ‡å‡†æœ¯è¯­: 'å¥—å£³'ã€'å¤§æ¨¡å‹'ã€'K8s'ã€'ELK'")
    info("  â€¢ åŒ…å«å¤šç§æ•°æ®ç±»å‹: æ•°å­—ã€åˆ—è¡¨ã€å¸ƒå°”å€¼")
    info("  â€¢ æ–‡æœ¬ç»“æ„æ¾æ•£ï¼Œéœ€è¦æ ‡å‡†åŒ–")
    
    # =========================================================================
    # é˜¶æ®µ 1: Prompt 1.0 é¢„å¤„ç†
    # =========================================================================
    info("\n\n" + "=" * 80)
    info("ã€é˜¶æ®µ 1: Prompt 1.0 é¢„å¤„ç† (prompt_preprocessor)ã€‘")
    info("=" * 80)
    
    info("\nğŸ“‹ æœ¯è¯­æ˜ å°„è¡¨:")
    for old, new in list(TERM_MAPPING.items())[:8]:
        if new:
            info(f"    '{old}' â†’ '{new}'")
        else:
            info(f"    '{old}' â†’ (åˆ é™¤)")
    info("    ... (å…± {} æ¡æ˜ å°„)".format(len(TERM_MAPPING)))
    
    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = PromptPreprocessor(
        mode=ProcessingMode.DICTIONARY,
        term_mapping=TERM_MAPPING,
        ambiguity_blacklist=AMBIGUITY_BLACKLIST,
        use_mock_llm=USE_MOCK,  # æ ¹æ®é…ç½®é€‰æ‹©æ¨¡æ‹Ÿæˆ–çœŸå®LLM
        enable_deep_check=False  # å…³é—­æ·±åº¦æ£€æµ‹ä»¥ä¾¿æ¼”ç¤ºç»§ç»­
    )
    
    info("\n>>> å¼€å§‹é¢„å¤„ç†...")
    start_time = time.time()
    
    # æ‰§è¡Œé¢„å¤„ç†
    prompt10_result = preprocessor.process(
        RAW_INPUT,
        save_history=True,  # ä¿å­˜å†å²è®°å½•
        show_comparison=False
    )
    
    preprocessing_time = int((time.time() - start_time) * 1000)
    
    # å±•ç¤ºé¢„å¤„ç†ç»“æœ
    info("\n" + "â”€" * 80)
    info("ã€Prompt 1.0 å¤„ç†ç»“æœã€‘")
    info("â”€" * 80)
    
    info(f"\nâœ… å¤„ç†çŠ¶æ€: {prompt10_result.status}")
    info(f"â±ï¸  å¤„ç†è€—æ—¶: {preprocessing_time}ms")
    
    # å±•ç¤ºæœ¯è¯­æ›¿æ¢
    if prompt10_result.terminology_changes:
        info("\nğŸ“ æœ¯è¯­æ›¿æ¢è®°å½•:")
        for old, new in prompt10_result.terminology_changes.items():
            info(f"    '{old}' â†’ '{new}'")
    
    # å±•ç¤ºå¤„ç†æ­¥éª¤
    if prompt10_result.steps:
        info("\nğŸ“Š å¤„ç†æ­¥éª¤:")
        for step in prompt10_result.steps:
            info(f"    {step.step_index}. {step.step_name} ({step.duration_ms}ms)")
    
    info("\nğŸ“„ æ ‡å‡†åŒ–åçš„æ–‡æœ¬:")
    info("â”€" * 60)
    processed_text = prompt10_result.processed_text
    info(processed_text)
    info("â”€" * 60)
    
    # å¯¹æ¯”å±•ç¤º
    info("\nğŸ” å…³é”®å˜åŒ–å¯¹æ¯”:")
    comparisons = [
        ("é‚£ä¸ªï¼Œå¸®æˆ‘æä¸€ä¸ªRAGçš„å¥—å£³åº”ç”¨å§", "å¸®æˆ‘å¼€å‘ä¸€ä¸ªæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)çš„åŸºäºAPIå°è£…çš„åº”ç”¨"),
        ("å¤§æ¨¡å‹åšåº•åº§", "å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åšåº•åº§"),
        ("chainçš„è¯å¤æ‚ä¸€ç‚¹", "å¤„ç†é“¾(Chain)çš„è¯å¤æ‚ä¸€ç‚¹"),
        ("K8sé›†ç¾¤", "Kubernetesé›†ç¾¤"),
        ("ELKé‚£å¥—", "ELKæ—¥å¿—ç³»ç»Ÿ(Elasticsearch+Logstash+Kibana)é‚£å¥—"),
    ]
    for old_phrase, expected_new in comparisons:
        if old_phrase in RAW_INPUT:
            info(f"    åŸ: {old_phrase}")
            info(f"    æ–°: {expected_new}")
            info("")
    
    # =========================================================================
    # é˜¶æ®µ 2: Prompt 2.0 ç»“æ„åŒ–
    # =========================================================================
    info("\n\n" + "=" * 80)
    info("ã€é˜¶æ®µ 2: Prompt 2.0 ç»“æ„åŒ– (prompt_structurizer)ã€‘")
    info("=" * 80)
    
    info("\n>>> è¾“å…¥: Prompt 1.0 å¤„ç†åçš„æ ‡å‡†åŒ–æ–‡æœ¬")
    
    # ä½¿ç”¨ LLM å®ä½“æŠ½å–å™¨ï¼ˆæ ¹æ®é…ç½®é€‰æ‹©æ¨¡æ‹Ÿæˆ–çœŸå®ï¼‰
    extractor = LLMEntityExtractor(use_mock=USE_MOCK)
    
    # é˜¶æ®µ 2.1: è¯­ä¹‰æ‰«æ
    info("\n" + "â”€" * 60)
    info("ã€2.1 è¯­ä¹‰æ‰«æä¸å®ä½“å®šä½ (LLM-Layer)ã€‘")
    info("â”€" * 60)
    
    raw_entities = extractor.extract(processed_text)
    info(f"\nè¯†åˆ«åˆ° {len(raw_entities)} ä¸ªå€™é€‰å®ä½“:")
    
    for i, entity in enumerate(raw_entities[:10], 1):
        info(f"  {i:2}. [{entity['type']:8}] \"{entity['original_text'][:20]}{'...' if len(entity['original_text']) > 20 else ''}\"")
    if len(raw_entities) > 10:
        info(f"  ... è¿˜æœ‰ {len(raw_entities) - 10} ä¸ª")
    
    # é˜¶æ®µ 2.2: å¹»è§‰é˜²ç«å¢™
    info("\n" + "â”€" * 60)
    info("ã€2.2 å¹»è§‰é˜²ç«å¢™ä¸å­˜åœ¨æ€§æ ¡éªŒ (Code-Layer)ã€‘")
    info("â”€" * 60)
    
    firewall = HallucinationFirewall()
    validated_entities = []
    rejected = []
    
    for entity in raw_entities:
        is_valid, msg = firewall.validate_existence(entity, processed_text)
        if is_valid:
            # ä¿®æ­£ç´¢å¼•
            if not firewall.validate_index(entity, processed_text):
                snippet = entity['original_text']
                idx = processed_text.find(snippet)
                if idx != -1:
                    entity['start_index'] = idx
                    entity['end_index'] = idx + len(snippet)
            validated_entities.append(entity)
        else:
            rejected.append(entity)
    
    info(f"\nâœ… é€šè¿‡éªŒè¯: {len(validated_entities)} ä¸ª")
    info(f"âŒ è¢«æ‹’ç» (å¹»è§‰): {len(rejected)} ä¸ª")
    for r in rejected:
        warning(f"    æ‹’ç»: \"{r['original_text'][:30]}...\" - ä¸å­˜åœ¨äºåŸæ–‡")
    
    # é˜¶æ®µ 2.3: å†²çªè§£å†³
    info("\n" + "â”€" * 60)
    info("ã€2.3 é‡å å®ä½“å†²çªè§£å†³ (æœ€é•¿è¦†ç›–åŸåˆ™)ã€‘")
    info("â”€" * 60)
    
    resolver = EntityConflictResolver()
    resolved_entities = resolver.resolve_overlaps(validated_entities)
    
    removed_count = len(validated_entities) - len(resolved_entities)
    info(f"\nå†²çªè§£å†³: {len(validated_entities)} â†’ {len(resolved_entities)} ä¸ª (ç§»é™¤ {removed_count} ä¸ªé‡å )")
    
    # é˜¶æ®µ 2.4: å¼ºç±»å‹æ¸…æ´—
    info("\n" + "â”€" * 60)
    info("ã€2.4 å¼ºç±»å‹æ¸…æ´—ä¸è½¬æ¢ (Code-Layer)ã€‘")
    info("â”€" * 60)
    
    cleaner = TypeCleaner()
    variable_metas = []
    
    info("\nç±»å‹è½¬æ¢è¯¦æƒ…:")
    for entity in resolved_entities:
        cleaned_value, actual_type = cleaner.clean(entity['value'], entity['type'])
        
        var_meta = VariableMeta(
            name=entity['name'],
            original_text=entity['original_text'],
            value=cleaned_value,
            data_type=actual_type,
            start_index=entity['start_index'],
            end_index=entity['end_index']
        )
        variable_metas.append(var_meta)
        
        # æ˜¾ç¤ºæœ‰æ„ä¹‰çš„è½¬æ¢
        if str(entity['value']) != str(cleaned_value) or entity['type'] != actual_type:
            info(f"  ğŸ”„ \"{entity['original_text'][:15]}{'...' if len(entity['original_text']) > 15 else ''}\":")
            info(f"      {entity['value']} ({entity['type']}) â†’ {cleaned_value} ({actual_type})")
    
    # é˜¶æ®µ 2.5: æ¨¡æ¿ç”Ÿæˆ
    info("\n" + "â”€" * 60)
    info("ã€2.5 æ¨¡æ¿ç”Ÿæˆä¸å˜é‡æ³¨å…¥ (Code-Layer)ã€‘")
    info("â”€" * 60)
    
    sorted_vars = sorted(variable_metas, key=lambda v: v.start_index, reverse=True)
    template = processed_text
    
    for var in sorted_vars:
        placeholder = f"{{{{{var.name}}}}}"
        template = template[:var.start_index] + placeholder + template[var.end_index:]
    
    info("\nğŸ“ ç”Ÿæˆçš„æ¨¡æ¿ (Prompt 2.0):")
    info("â”€" * 60)
    # åˆ†è¡Œæ˜¾ç¤ºæ¨¡æ¿
    for line in template.split('\n'):
        info(line)
    info("â”€" * 60)
    
    # =========================================================================
    # æœ€ç»ˆè¾“å‡º
    # =========================================================================
    info("\n\n" + "=" * 80)
    info("ã€æœ€ç»ˆè¾“å‡º: å˜é‡æ³¨å†Œè¡¨ (Variable Registry)ã€‘")
    info("=" * 80)
    
    variable_registry = []
    for var in variable_metas:
        registry_entry = {
            "variable": var.name,
            "original_text": var.original_text,
            "value": var.value,
            "type": var.data_type,
        }
        variable_registry.append(registry_entry)
    
    info(json.dumps(variable_registry, indent=2, ensure_ascii=False))

    # =========================================================================
    # é˜¶æ®µ3: Prompt 3.0 DSL ç¼–è¯‘å‡†å¤‡
    # =========================================================================
    info("\n>>> å‡†å¤‡ Prompt 2.0 ç»“æœç”¨äº DSL ç¼–è¯‘...")

    # åˆ›å»º Prompt20Result å¯¹è±¡
    prompt20_result = create_prompt20_result(
        source_prompt10_id=prompt10_result.id,
        original_text=processed_text,
        template_text=template,
        variables=variable_metas,
        processing_time_ms=0  # å®é™…åº”è¯¥è®¡ç®—ï¼Œè¿™é‡Œå…ˆè®¾ä¸º0
    )

    # è½¬æ¢ä¸º DSL ç¼–è¯‘å™¨è¾“å…¥æ ¼å¼
    dsl_input = convert_prompt20_to_dsl_input(prompt20_result)
    info(f"âœ… Prompt 2.0 ç»“æœå·²å‡†å¤‡ï¼ŒåŒ…å« {len(prompt20_result.variables)} ä¸ªå˜é‡")

    # =========================================================================
    # éªŒè¯ä¸åº”ç”¨ç¤ºä¾‹
    # =========================================================================
    info("\n\n" + "=" * 80)
    info("ã€éªŒè¯: æ¨¡æ¿å›å¡«è¿˜åŸã€‘")
    info("=" * 80)
    
    filled = template
    for var in variable_metas:
        placeholder = f"{{{{{var.name}}}}}"
        filled = filled.replace(placeholder, var.original_text)
    
    is_match = filled == processed_text
    info(f"\nè¿˜åŸåä¸ Prompt 1.0 ä¸€è‡´: {'âœ… æ˜¯' if is_match else 'âŒ å¦'}")
    
    # å®é™…åº”ç”¨ç¤ºä¾‹
    info("\n\n" + "=" * 80)
    info("ã€å®é™…åº”ç”¨: åŠ¨æ€å‚æ•°è°ƒæ•´ç¤ºä¾‹ã€‘")
    info("=" * 80)
    
    # æ¨¡æ‹Ÿå‚æ•°è°ƒæ•´
    adjustments = {
        "duration_weeks": ("8å‘¨", "12å‘¨"),
        "budget_wan": ("50ä¸‡", "80ä¸‡"),
        "team_size": ("5ä¸ªäºº", "10ä¸ªäºº"),
        "context_rounds": ("20è½®", "50è½®"),
    }
    
    info("\nç”¨æˆ·è°ƒæ•´å‚æ•°:")
    for key, (old_val, new_val) in adjustments.items():
        info(f"  â€¢ {old_val} â†’ {new_val}")
    
    customized = template
    for var in variable_metas:
        placeholder = f"{{{{{var.name}}}}}"
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›¿æ¢
        replaced = False
        for key, (old_val, new_val) in adjustments.items():
            if key in var.name and var.original_text == old_val:
                customized = customized.replace(placeholder, new_val)
                replaced = True
                break
        if not replaced:
            customized = customized.replace(placeholder, var.original_text)
    
    info("\nğŸ“„ å®šåˆ¶åçš„éœ€æ±‚æ–‡æ¡£:")
    info("â”€" * 60)
    for line in customized.split('\n'):
        info(line)
    info("â”€" * 60)

    # =========================================================================
    # é˜¶æ®µ3: Prompt 3.0 DSL ç¼–è¯‘
    # =========================================================================
    info("\n\n" + "=" * 80)
    info("ã€é˜¶æ®µ 3: Prompt 3.0 DSL ç¼–è¯‘ (prompt_dslcompiler)ã€‘")
    info("=" * 80)

    info("\n>>> å¼€å§‹ DSL ç¼–è¯‘...")
    start_time = time.time()

    # åˆ›å»ºè‡ªæˆ‘ä¿®æ­£å¾ªç¯ç¼–è¯‘å™¨ï¼ˆç­–ç•¥ Dï¼‰
    compiler = SelfCorrectionLoop(max_retries=3, use_mock=USE_MOCK, auto_fix_threshold=3)
    success, dsl_code, validation_result, compile_history = compiler.compile_with_retry(dsl_input)

    dsl_compile_time = int((time.time() - start_time) * 1000)

    # æ£€æŸ¥ç¼–è¯‘çŠ¶æ€
    compile_decision = compile_history.get('final_decision', 'unknown')

    if success or compile_decision == 'partial_auto_fixed':
        if compile_decision == 'partial_auto_fixed':
            warning(f"\nâš ï¸  DSL éƒ¨åˆ†ä¿®å¤æˆåŠŸï¼ˆè‡ªåŠ¨ä¿®å¤åä»æœ‰å°‘é‡é”™è¯¯ï¼‰ï¼è€—æ—¶: {dsl_compile_time}ms")
        else:
            info(f"\nâœ… DSL ç¼–è¯‘æˆåŠŸï¼è€—æ—¶: {dsl_compile_time}ms")
        info("\nğŸ“„ ç”Ÿæˆçš„ DSL ä»£ç :")
        info("â”€" * 60)
        for line in dsl_code.split('\n'):
            info(line)
        info("â”€" * 60)

        info("\nğŸ“Š éªŒè¯ç»“æœ:")
        info(validation_result.get_report())

        # å¦‚æœæ˜¯éƒ¨åˆ†ä¿®å¤çŠ¶æ€ï¼Œæ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
        if compile_decision == 'partial_auto_fixed':
            warning("\nâš ï¸  æ³¨æ„ï¼šDSL ä»£ç ä»æœ‰å°‘é‡éªŒè¯é”™è¯¯ï¼Œä½†å·²å°è¯•è¿›å…¥ä»£ç ç”Ÿæˆé˜¶æ®µ")
            if validation_result.errors:
                info("å‰©ä½™é”™è¯¯:")
                for err in validation_result.errors:
                    error(f"  {err}")

        # =========================================================================
        # é˜¶æ®µ 4: Prompt 4.0 ä»£ç ç”Ÿæˆ
        # =========================================================================
        info("\n\n" + "=" * 80)
        info("ã€é˜¶æ®µ 4: Prompt 4.0 ä»£ç ç”Ÿæˆ (prompt_codegenetate)ã€‘")
        info("=" * 80)

        info("\n>>> å¼€å§‹ä»£ç ç”Ÿæˆ...")
        start_time_codegen = time.time()

        # åˆ›å»ºä»£ç ç¼–è¯‘å™¨
        code_compiler = WaActCompiler()
        try:
            modules, main_code, compile_details = code_compiler.compile(
                dsl_code,
                clustering_strategy="hybrid",
                visualize=False
            )

            codegen_time = int((time.time() - start_time_codegen) * 1000)
            info(f"\nâœ… ä»£ç ç”ŸæˆæˆåŠŸï¼è€—æ—¶: {codegen_time}ms")

            # æ˜¾ç¤ºç”Ÿæˆçš„æ¨¡å—
            info("\nğŸ“¦ ç”Ÿæˆçš„æ¨¡å—:")
            for i, module in enumerate(modules, 1):
                info(f"  {i}. {module.name} ({'async' if module.is_async else 'sync'})")

            # æ˜¾ç¤ºä¸»å·¥ä½œæµä»£ç 
            info("\nğŸ“„ ä¸»å·¥ä½œæµä»£ç :")
            info("â”€" * 60)
            for line in main_code.split('\n'):
                info(line)
            info("â”€" * 60)

            # å¯¼å‡ºåˆ°æ–‡ä»¶
            output_file = "generated_workflow.py"
            code_compiler.export_to_file(modules, main_code, output_file)
            info(f"\nğŸ’¾ ä»£ç å·²å¯¼å‡ºåˆ°: {output_file}")
        except Exception as e:
            error(f"\nâŒ ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            warning("DSL ä»£ç å­˜åœ¨ä¸¥é‡é”™è¯¯ï¼Œæ— æ³•ç”Ÿæˆå¯æ‰§è¡Œä»£ç ")
            modules = []
            main_code = ""
            compile_details = {
                'step1_parsing': {'status': 'failed', 'reason': str(e)},
                'step2_dependency': {'status': 'skipped', 'reason': 'Parsing failed'},
                'step3_clustering': {'status': 'skipped', 'reason': 'Parsing failed'},
                'step4_generation': {'status': 'skipped', 'reason': 'Parsing failed'},
                'step5_orchestration': {'status': 'skipped', 'reason': 'Parsing failed'}
            }
            codegen_time = int((time.time() - start_time_codegen) * 1000)
    else:
        warning(f"\nâš ï¸  DSL ç¼–è¯‘å¤±è´¥ï¼è€—æ—¶: {dsl_compile_time}ms")
        info("\nğŸ“„ ç”Ÿæˆçš„ DSL ä»£ç  (æœ‰é”™è¯¯):")
        info("â”€" * 60)
        for line in dsl_code.split('\n'):
            info(line)
        info("â”€" * 60)

        info("\nâŒ éªŒè¯é”™è¯¯:")
        for err in validation_result.errors[:5]:
            error(f"  {err}")

        # DSL ç¼–è¯‘å¤±è´¥æ—¶ï¼Œè·³è¿‡ä»£ç ç”Ÿæˆé˜¶æ®µï¼Œä½†ä¿ç•™ç©ºæ•°æ®
        info("\n>>> DSL ç¼–è¯‘å¤±è´¥ï¼Œè·³è¿‡ä»£ç ç”Ÿæˆé˜¶æ®µ")
        modules = []
        main_code = ""
        compile_details = {
            'step1_parsing': {'status': 'skipped', 'reason': 'DSL compilation failed'},
            'step2_dependency': {'status': 'skipped', 'reason': 'DSL compilation failed'},
            'step3_clustering': {'status': 'skipped', 'reason': 'DSL compilation failed'},
            'step4_generation': {'status': 'skipped', 'reason': 'DSL compilation failed'},
            'step5_orchestration': {'status': 'skipped', 'reason': 'DSL compilation failed'}
        }
        codegen_time = 0

    # =========================================================================
    # æ€»ç»“
    # =========================================================================
    info("\n\n" + "â–ˆ" * 80)
    info("â–ˆ" + " " * 32 + "æµæ°´çº¿æ€»ç»“" + " " * 34 + "â–ˆ")
    info("â–ˆ" * 80)
    
    info(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š å¤„ç†ç»Ÿè®¡                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ åŸå§‹è¾“å…¥é•¿åº¦: {len(RAW_INPUT):4} å­—ç¬¦                                              â”‚
â”‚ æ ‡å‡†åŒ–åé•¿åº¦: {len(processed_text):4} å­—ç¬¦                                              â”‚
â”‚ æœ¯è¯­æ›¿æ¢æ•°é‡: {len(prompt10_result.terminology_changes):4} å¤„                                              â”‚
â”‚ è¯†åˆ«å˜é‡æ•°é‡: {len(variable_metas):4} ä¸ª                                              â”‚
â”‚ å˜é‡ç±»å‹åˆ†å¸ƒ:                                                                â”‚
â”‚   - Integer: {len([v for v in variable_metas if v.data_type == 'Integer']):2} ä¸ª                                                        â”‚
â”‚   - String:  {len([v for v in variable_metas if v.data_type == 'String']):2} ä¸ª                                                        â”‚
â”‚   - List:    {len([v for v in variable_metas if v.data_type == 'List']):2} ä¸ª                                                        â”‚
â”‚   - Boolean: {len([v for v in variable_metas if v.data_type == 'Boolean']):2} ä¸ª                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¯ é¢„å¤„ç†æ¨¡å—è´¡çŒ® (Prompt 1.0 é¢„å¤„ç†)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ å£è¯­åŒ–è¡¨è¾¾æ¶ˆé™¤: 'é‚£ä¸ª'ã€'å§'ã€'å˜›'ã€'æ' â†’ è§„èŒƒä¹¦é¢è¯­                     â”‚
â”‚ â€¢ æœ¯è¯­æ ‡å‡†åŒ–: 'å¥—å£³'â†’'åŸºäºAPIå°è£…çš„åº”ç”¨', 'K8s'â†’'Kubernetes'                â”‚
â”‚ â€¢ è¯­æ³•ä¿®æ­£: ä½¿æ–‡æœ¬ç»“æ„æ›´æ¸…æ™°è§„èŒƒ                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¯ ç»“æ„åŒ–æ¨¡å—è´¡çŒ® (Prompt 2.0 ç»“æ„åŒ–)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ å®ä½“æŠ½å–: ä»æ ‡å‡†åŒ–æ–‡æœ¬ä¸­è¯†åˆ«æ‰€æœ‰å¯å‚æ•°åŒ–çš„å˜é‡                            â”‚
â”‚ â€¢ å¹»è§‰é˜²å¾¡: æ‹’ç» LLM è™šæ„çš„ä¸å­˜åœ¨å®ä½“                                        â”‚
â”‚ â€¢ ç±»å‹æ¸…æ´—: '8å‘¨'â†’8(Integer), 'éœ€è¦æ”¯æŒ'â†’True(Boolean)                      â”‚
â”‚ â€¢ æ¨¡æ¿ç”Ÿæˆ: ç”Ÿæˆå¯å¤ç”¨çš„å‚æ•°åŒ–æ¨¡æ¿                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")
    
    info("â–ˆ" * 80)
    info("â–ˆ" + " " * 32 + "æ¼”ç¤ºå®Œæˆ" + " " * 36 + "â–ˆ")
    info("â–ˆ" * 80)
    
    # =========================================================================
    # ä¿å­˜å®Œæ•´æµæ°´çº¿å†å²è®°å½•
    # =========================================================================
    info("\n>>> ä¿å­˜æµæ°´çº¿å†å²è®°å½•...")
    
    # ç»Ÿè®¡å˜é‡ç±»å‹
    type_stats = {}
    for var in variable_metas:
        dtype = var.data_type
        type_stats[dtype] = type_stats.get(dtype, 0) + 1
    
    # å‡†å¤‡ç¬¬å››é˜¶æ®µæ•°æ®
    prompt40_modules_dict = []
    prompt40_module_count = 0
    prompt40_main_code = ""
    prompt40_time_ms = 0
    prompt40_step1_parsing = {}
    prompt40_step2_dependency = {}
    prompt40_step3_clustering = {}
    prompt40_step4_generation = {}
    prompt40_step5_orchestration = {}

    if success:
        # è½¬æ¢ ModuleDefinition å¯¹è±¡ä¸ºå­—å…¸ï¼Œæ’é™¤ä¸å¯åºåˆ—åŒ–çš„å­—æ®µ
        for module in modules:
            module_dict = {
                'name': module.name,
                'inputs': module.inputs,
                'outputs': module.outputs,
                'is_async': module.is_async,
            }
            prompt40_modules_dict.append(module_dict)
        prompt40_module_count = len(modules)
        prompt40_main_code = main_code
        prompt40_time_ms = codegen_time

        # ä¿å­˜ç¼–è¯‘æ­¥éª¤è¯¦æƒ…
        prompt40_step1_parsing = compile_details.get('step1_parsing', {})
        prompt40_step2_dependency = compile_details.get('step2_dependency', {})
        prompt40_step3_clustering = compile_details.get('step3_clustering', {})
        prompt40_step4_generation = compile_details.get('step4_generation', {})
        prompt40_step5_orchestration = compile_details.get('step5_orchestration', {})

    # åˆ›å»ºæµæ°´çº¿å†å²è®°å½•
    pipeline_history = PipelineHistory(
        pipeline_id=generate_id(),
        timestamp=get_timestamp(),
        raw_input=RAW_INPUT,

        # é˜¶æ®µ1ç»“æœ
        prompt10_id=prompt10_result.id,
        prompt10_original=prompt10_result.original_text,
        prompt10_processed=prompt10_result.processed_text,
        prompt10_mode=prompt10_result.mode,
        prompt10_steps=[s.to_dict() for s in prompt10_result.steps],
        prompt10_terminology_changes=prompt10_result.terminology_changes,
        prompt10_ambiguity_detected=prompt10_result.ambiguity_detected,
        prompt10_status=prompt10_result.status,
        prompt10_time_ms=prompt10_result.processing_time_ms,

        # é˜¶æ®µ2ç»“æœ
        prompt20_id=generate_id(),
        prompt20_template=template,
        prompt20_variables=variable_registry,
        prompt20_variable_count=len(variable_metas),
        prompt20_type_stats=type_stats,
        prompt20_extraction_log=[],
        prompt20_time_ms=0,

        # é˜¶æ®µ3ç»“æœ (DSLç¼–è¯‘) - æ— è®ºæˆåŠŸå¤±è´¥éƒ½è®°å½• DSL ä»£ç å’ŒéªŒè¯ç»“æœ
        prompt30_id=generate_id(),
        prompt30_dsl_code=dsl_code,  # æ€»æ˜¯è®°å½• DSL ä»£ç 
        prompt30_validation_result=validation_result.to_dict(),  # æ€»æ˜¯è®°å½•éªŒè¯ç»“æœ
        prompt30_time_ms=dsl_compile_time,
        prompt30_compile_history=compile_history,  # æ–°å¢ï¼šç¼–è¯‘å†å²ï¼ˆç­–ç•¥ Dï¼‰
        prompt30_success=success,  # æ–°å¢ï¼šç¼–è¯‘æˆåŠŸæ ‡å¿—

        # é˜¶æ®µ4ç»“æœ (ä»£ç ç”Ÿæˆ)
        prompt40_id=generate_id(),
        prompt40_modules=prompt40_modules_dict,
        prompt40_module_count=prompt40_module_count,
        prompt40_main_code=prompt40_main_code,
        prompt40_time_ms=prompt40_time_ms,

        # é˜¶æ®µ4å­æ­¥éª¤è¯¦æƒ…
        prompt40_step1_parsing=prompt40_step1_parsing,
        prompt40_step2_dependency=prompt40_step2_dependency,
        prompt40_step3_clustering=prompt40_step3_clustering,
        prompt40_step4_generation=prompt40_step4_generation,
        prompt40_step5_orchestration=prompt40_step5_orchestration,

        # æ•´ä½“çŠ¶æ€ - æ ¹æ®ç¼–è¯‘å†³ç­–åˆ¤æ–­
        total_time_ms=prompt10_result.processing_time_ms + dsl_compile_time + prompt40_time_ms,
        error_message=None
    )

    # æ ¹æ®ç¼–è¯‘å†³ç­–æ›´æ–°æ•´ä½“çŠ¶æ€
    if compile_decision == 'success':
        pipeline_history.overall_status = "success"
    elif compile_decision == 'partial_auto_fixed':
        pipeline_history.overall_status = "partial"  # DSLæœ‰è¯¯ä½†èƒ½ç”Ÿæˆä»£ç 
    else:
        pipeline_history.overall_status = "partial"  # DSLå¤±è´¥
    
    # ä¿å­˜å†å²è®°å½•
    history_manager = HistoryManager()
    history_manager.save_pipeline_history(pipeline_history)
    
    info(f"âœ… æµæ°´çº¿å†å²å·²ä¿å­˜: {pipeline_history.pipeline_id}")
    info(f"ğŸ“ æŸ¥çœ‹å†å²: python3 view_history.py pipeline")
    info(f"ğŸ“„ å¯¼å‡ºæŠ¥å‘Š: python3 view_history.py export-pipeline")


if __name__ == "__main__":
    run_full_pipeline()
