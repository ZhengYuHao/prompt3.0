"""
2.py æ¨¡å—åŠŸèƒ½æ¼”ç¤º
å±•ç¤ºå®ä½“æŠ½å–ä¸å˜é‡å®šä¹‰çš„å®Œæ•´æµç¨‹
"""

import json
import re
from typing import List, Dict, Any

# å¯¼å…¥ 2.py çš„æ ¸å¿ƒç»„ä»¶
import sys
sys.path.insert(0, '.')

from logger import info, warning, error

# ============================================================================
# å¢å¼ºçš„æ¨¡æ‹Ÿ LLM æŠ½å–å™¨ï¼ˆæ¨¡æ‹ŸçœŸå® LLM çš„å¤æ‚è¾“å‡ºï¼‰
# ============================================================================

class EnhancedMockExtractor:
    """å¢å¼ºç‰ˆæ¨¡æ‹ŸæŠ½å–å™¨ï¼Œæ¨¡æ‹ŸçœŸå® LLM çš„å„ç§æƒ…å†µ"""
    
    def extract(self, text: str) -> List[Dict]:
        """
        æ¨¡æ‹Ÿ LLM æŠ½å–ç»“æœï¼ŒåŒ…å«ï¼š
        - æ­£ç¡®çš„å®ä½“
        - å¹»è§‰å®ä½“ï¼ˆæµ‹è¯•é˜²ç«å¢™ï¼‰
        - é‡å å®ä½“ï¼ˆæµ‹è¯•å†²çªè§£å†³ï¼‰
        - å¤šç§æ•°æ®ç±»å‹
        """
        entities = []
        
        # ===== 1. Integer ç±»å‹ï¼šæ•°å­—+å•ä½ =====
        for match in re.finditer(r'(\d+)(å¹´|å‘¨|æœˆ|å¤©|å°æ—¶|äºº|ä¸ª|å|æ¬¡)', text):
            unit_map = {
                'å¹´': 'years', 'å‘¨': 'weeks', 'æœˆ': 'months', 
                'å¤©': 'days', 'å°æ—¶': 'hours', 'äºº': 'people',
                'ä¸ª': 'count', 'å': 'people', 'æ¬¡': 'times'
            }
            entities.append({
                "name": f"{unit_map.get(match.group(2), 'value')}_{len(entities)}",
                "original_text": match.group(0),
                "start_index": match.start(),
                "end_index": match.end(),
                "type": "Integer",
                "value": match.group(0)  # åŸå§‹æ–‡æœ¬ï¼Œè®© TypeCleaner æå–æ•°å­—
            })
        
        # ===== 2. String ç±»å‹ï¼šä¸“ä¸šæœ¯è¯­/è§’è‰² =====
        tech_terms = [
            ("Javaç¨‹åºå‘˜", "role"),
            ("Pythonå¼€å‘", "skill"),
            ("æ•°æ®åˆ†æ", "focus_area"),
            ("æœºå™¨å­¦ä¹ ", "focus_area"),
            ("å‰ç«¯å¼€å‘", "skill"),
            ("åç«¯æ¶æ„", "skill"),
            ("é¡¹ç›®ç»ç†", "role"),
            ("RAGç³»ç»Ÿ", "system_type"),
            ("å‘é‡æ•°æ®åº“", "component"),
            ("Embeddingæ¨¡å‹", "component"),
        ]
        for term, category in tech_terms:
            if term in text:
                idx = text.find(term)
                entities.append({
                    "name": f"{category}_{len(entities)}",
                    "original_text": term,
                    "start_index": idx,
                    "end_index": idx + len(term),
                    "type": "String",
                    "value": term
                })
        
        # ===== 3. List ç±»å‹ï¼šé€—å·/é¡¿å·åˆ†éš” =====
        list_patterns = [
            (r'åŒ…æ‹¬[ï¼š:]\s*([^ã€‚ï¼Œ]+(?:[ã€,ï¼Œ][^ã€‚ï¼Œ]+)+)', 'items'),
            (r'æ¶µç›–[ï¼š:]\s*([^ã€‚ï¼Œ]+(?:[ã€,ï¼Œ][^ã€‚ï¼Œ]+)+)', 'coverage'),
            (r'æŠ€æœ¯æ ˆ[ï¼š:]\s*([^ã€‚]+)', 'tech_stack'),
        ]
        for pattern, name in list_patterns:
            match = re.search(pattern, text)
            if match:
                entities.append({
                    "name": f"{name}_{len(entities)}",
                    "original_text": match.group(1),
                    "start_index": match.start(1),
                    "end_index": match.end(1),
                    "type": "List",
                    "value": match.group(1)
                })
        
        # ===== 4. Boolean ç±»å‹ =====
        bool_patterns = [
            (r'(éœ€è¦|ä¸éœ€è¦)(è®¤è¯|å®¡æ ¸|æµ‹è¯•)', 'require'),
            (r'(æ˜¯å¦)(å¿…é¡»|å¯é€‰)', 'optional'),
        ]
        for pattern, name in bool_patterns:
            match = re.search(pattern, text)
            if match:
                entities.append({
                    "name": f"{name}_{len(entities)}",
                    "original_text": match.group(0),
                    "start_index": match.start(),
                    "end_index": match.end(),
                    "type": "Boolean",
                    "value": match.group(1)  # "éœ€è¦" æˆ– "ä¸éœ€è¦"
                })
        
        # ===== 5. æ¨¡æ‹Ÿ LLM å¹»è§‰ï¼ˆé˜²ç«å¢™æµ‹è¯•ï¼‰ =====
        # æ·»åŠ ä¸€ä¸ªåŸæ–‡ä¸­ä¸å­˜åœ¨çš„å®ä½“
        entities.append({
            "name": "hallucination_test",
            "original_text": "è¿™æ˜¯LLMè™šæ„çš„å†…å®¹",  # åŸæ–‡ä¸­ä¸å­˜åœ¨
            "start_index": 999,
            "end_index": 1010,
            "type": "String",
            "value": "å¹»è§‰å†…å®¹"
        })
        
        # ===== 6. æ¨¡æ‹Ÿé‡å å®ä½“ï¼ˆå†²çªè§£å†³æµ‹è¯•ï¼‰ =====
        # å¦‚æœæœ‰ "3å¹´ç»éªŒ"ï¼ŒåŒæ—¶æ·»åŠ  "3å¹´" å’Œ "3å¹´ç»éªŒ"
        exp_match = re.search(r'(\d+å¹´)(ç»éªŒ|å·¥ä½œç»éªŒ)', text)
        if exp_match:
            # çŸ­å®ä½“
            entities.append({
                "name": "short_duration",
                "original_text": exp_match.group(1),  # "3å¹´"
                "start_index": exp_match.start(1),
                "end_index": exp_match.end(1),
                "type": "Integer",
                "value": exp_match.group(1)
            })
            # é•¿å®ä½“ï¼ˆåº”è¯¥è¢«ä¿ç•™ï¼‰
            entities.append({
                "name": "full_experience",
                "original_text": exp_match.group(0),  # "3å¹´ç»éªŒ"
                "start_index": exp_match.start(),
                "end_index": exp_match.end(),
                "type": "String",
                "value": exp_match.group(0)
            })
        
        return entities


# ============================================================================
# å¯¼å…¥ 2.py çš„æ ¸å¿ƒç±»
# ============================================================================

# è¯»å–å¹¶æ‰§è¡Œ 2.pyï¼ˆæ’é™¤ main éƒ¨åˆ†ï¼‰
with open('2.py', 'r', encoding='utf-8') as f:
    code = f.read()
    # åªæ‰§è¡Œåˆ° main å‡½æ•°ä¹‹å‰
    code_parts = code.split("# ========== ä½¿ç”¨ç¤ºä¾‹ ==========")
    exec(code_parts[0])


# ============================================================================
# æ¼”ç¤ºå‡½æ•°
# ============================================================================

def demo_complex_extraction():
    """æ¼”ç¤ºå¤æ‚åœºæ™¯ä¸‹çš„å®ä½“æŠ½å–"""
    
    # å¤æ‚æµ‹è¯•æ–‡æœ¬ï¼ˆåŒ…å«å¤šç§å®ä½“ç±»å‹ï¼‰
    test_text = """
è¯·ä¸ºä¸€ä½æœ‰5å¹´ç»éªŒçš„Javaç¨‹åºå‘˜è®¾è®¡ä¸€ä¸ªä¸ºæœŸ3å‘¨çš„åŸ¹è®­è®¡åˆ’ã€‚
åŸ¹è®­å†…å®¹åŒ…æ‹¬ï¼šPythonå¼€å‘ã€æ•°æ®åˆ†æã€æœºå™¨å­¦ä¹ åŸºç¡€ã€‚
å›¢é˜Ÿè§„æ¨¡ä¸º8äººï¼Œæ¯å‘¨åŸ¹è®­3æ¬¡ï¼Œæ¯æ¬¡2å°æ—¶ã€‚
æŠ€æœ¯æ ˆ: FastAPIã€PostgreSQLã€Redisã€Dockerã€‚
è¯¥åŸ¹è®­éœ€è¦è®¤è¯ï¼Œå®Œæˆåå¯è·å¾—å†…éƒ¨èµ„è´¨è¯ä¹¦ã€‚
æœ€ç»ˆç›®æ ‡æ˜¯è®©å­¦å‘˜èƒ½å¤Ÿç‹¬ç«‹å¼€å‘RAGç³»ç»Ÿï¼Œæ¶µç›–å‘é‡æ•°æ®åº“ã€Embeddingæ¨¡å‹çš„ä½¿ç”¨ã€‚
""".strip()

    info("=" * 80)
    info("ã€2.py æ¨¡å—åŠŸèƒ½å®Œæ•´æ¼”ç¤ºã€‘")
    info("=" * 80)
    
    info("\n" + "â”€" * 80)
    info("ã€è¾“å…¥æ–‡æœ¬ - Prompt 1.0ã€‘")
    info("â”€" * 80)
    info(test_text)
    
    # ===== é˜¶æ®µ 2.1: è¯­ä¹‰æ‰«æ =====
    info("\n" + "=" * 80)
    info("ã€é˜¶æ®µ 2.1: è¯­ä¹‰æ‰«æä¸å®ä½“å®šä½ (LLM-Layer)ã€‘")
    info("=" * 80)
    
    extractor = EnhancedMockExtractor()
    raw_entities = extractor.extract(test_text)
    
    info(f"\nLLM è¯†åˆ«åˆ° {len(raw_entities)} ä¸ªå€™é€‰å®ä½“:")
    for i, entity in enumerate(raw_entities, 1):
        info(f"  {i}. [{entity['type']:8}] \"{entity['original_text']}\" "
             f"(ä½ç½®: {entity['start_index']}-{entity['end_index']})")
    
    # ===== é˜¶æ®µ 2.2: å¹»è§‰é˜²ç«å¢™ =====
    info("\n" + "=" * 80)
    info("ã€é˜¶æ®µ 2.2: å¹»è§‰é˜²ç«å¢™ä¸å­˜åœ¨æ€§æ ¡éªŒ (Code-Layer)ã€‘")
    info("=" * 80)
    
    firewall = HallucinationFirewall()
    validated_entities = []
    rejected_count = 0
    
    for entity in raw_entities:
        is_valid, msg = firewall.validate_existence(entity, test_text)
        if is_valid:
            # æ£€æŸ¥ç´¢å¼•
            if not firewall.validate_index(entity, test_text):
                # è‡ªåŠ¨ä¿®æ­£ç´¢å¼•
                snippet = entity['original_text']
                idx = test_text.find(snippet)
                if idx != -1:
                    entity['start_index'] = idx
                    entity['end_index'] = idx + len(snippet)
                    info(f"  âš ï¸  ç´¢å¼•å·²ä¿®æ­£: \"{snippet}\" -> ä½ç½® {idx}-{idx+len(snippet)}")
            
            validated_entities.append(entity)
            info(f"  âœ… éªŒè¯é€šè¿‡: \"{entity['original_text']}\"")
        else:
            rejected_count += 1
            warning(f"  âŒ æ‹’ç» (å¹»è§‰æ£€æµ‹): \"{entity['original_text']}\" - {msg}")
    
    info(f"\nğŸ“Š é˜²ç«å¢™ç»Ÿè®¡: é€šè¿‡ {len(validated_entities)} ä¸ª, æ‹’ç» {rejected_count} ä¸ª")
    
    # ===== å†²çªè§£å†³ =====
    info("\n" + "=" * 80)
    info("ã€é‡å å®ä½“å†²çªè§£å†³ (æœ€é•¿è¦†ç›–åŸåˆ™)ã€‘")
    info("=" * 80)
    
    resolver = EntityConflictResolver()
    before_count = len(validated_entities)
    resolved_entities = resolver.resolve_overlaps(validated_entities)
    after_count = len(resolved_entities)
    
    if before_count != after_count:
        info(f"  ğŸ”„ å†²çªè§£å†³: {before_count} ä¸ª -> {after_count} ä¸ª (ç§»é™¤ {before_count - after_count} ä¸ªé‡å å®ä½“)")
        info("  ğŸ’¡ ç¤ºä¾‹: \"3å¹´\" ä¸ \"3å¹´ç»éªŒ\" é‡å ï¼Œä¿ç•™æ›´é•¿çš„ \"3å¹´ç»éªŒ\"")
    else:
        info(f"  âœ… æ— å†²çª: ä¿ç•™å…¨éƒ¨ {after_count} ä¸ªå®ä½“")
    
    # ===== é˜¶æ®µ 2.3: å¼ºç±»å‹æ¸…æ´— =====
    info("\n" + "=" * 80)
    info("ã€é˜¶æ®µ 2.3: å¼ºç±»å‹æ¸…æ´—ä¸è½¬æ¢ (Code-Layer)ã€‘")
    info("=" * 80)
    
    cleaner = TypeCleaner()
    variable_metas = []
    
    for entity in resolved_entities:
        original_value = entity['value']
        original_type = entity['type']
        cleaned_value, actual_type = cleaner.clean(original_value, original_type)
        
        var_meta = VariableMeta(
            name=entity['name'],
            original_text=entity['original_text'],
            value=cleaned_value,
            data_type=actual_type,
            start_index=entity['start_index'],
            end_index=entity['end_index']
        )
        variable_metas.append(var_meta)
        
        # æ˜¾ç¤ºç±»å‹è½¬æ¢è¯¦æƒ…
        type_changed = original_type != actual_type
        value_changed = str(original_value) != str(cleaned_value)
        
        if type_changed or value_changed:
            info(f"  ğŸ”„ \"{entity['original_text']}\":")
            info(f"      åŸå§‹: {original_value} ({original_type})")
            info(f"      è½¬æ¢: {cleaned_value} ({actual_type})")
        else:
            info(f"  âœ… \"{entity['original_text']}\": {cleaned_value} ({actual_type})")
    
    # ===== é˜¶æ®µ 2.4: æ¨¡æ¿ç”Ÿæˆ =====
    info("\n" + "=" * 80)
    info("ã€é˜¶æ®µ 2.4: æ¨¡æ¿ç”Ÿæˆä¸å˜é‡æ³¨å…¥ (Code-Layer)ã€‘")
    info("=" * 80)
    
    # æŒ‰ä½ç½®å€’åºæ’åºï¼Œä»åå¾€å‰æ›¿æ¢
    sorted_vars = sorted(variable_metas, key=lambda v: v.start_index, reverse=True)
    template = test_text
    
    for var in sorted_vars:
        placeholder = f"{{{{{var.name}}}}}"
        template = template[:var.start_index] + placeholder + template[var.end_index:]
    
    info("\nã€ç”Ÿæˆçš„æ¨¡æ¿ - Prompt 2.0ã€‘")
    info("â”€" * 80)
    info(template)
    
    # ===== å˜é‡æ³¨å†Œè¡¨ =====
    info("\n" + "=" * 80)
    info("ã€å˜é‡æ³¨å†Œè¡¨ (Variable Registry)ã€‘")
    info("=" * 80)
    
    variable_registry = []
    for var in variable_metas:
        registry_entry = {
            "variable": var.name,
            "original_text": var.original_text,
            "value": var.value,
            "type": var.data_type,
            "position": f"{var.start_index}-{var.end_index}"
        }
        variable_registry.append(registry_entry)
    
    info(json.dumps(variable_registry, indent=2, ensure_ascii=False))
    
    # ===== éªŒè¯ï¼šæ¨¡æ¿å›å¡« =====
    info("\n" + "=" * 80)
    info("ã€éªŒè¯: æ¨¡æ¿å›å¡«è¿˜åŸã€‘")
    info("=" * 80)
    
    filled_template = template
    for var in variable_metas:
        placeholder = f"{{{{{var.name}}}}}"
        filled_template = filled_template.replace(placeholder, var.original_text)
    
    is_identical = filled_template == test_text
    info(f"\nè¿˜åŸåä¸åŸæ–‡ä¸€è‡´: {'âœ… æ˜¯' if is_identical else 'âŒ å¦'}")
    
    if not is_identical:
        info("\nã€å·®å¼‚å¯¹æ¯”ã€‘")
        info(f"åŸæ–‡é•¿åº¦: {len(test_text)}, è¿˜åŸé•¿åº¦: {len(filled_template)}")
    
    # ===== ä½¿ç”¨ç¤ºä¾‹ =====
    info("\n" + "=" * 80)
    info("ã€å®é™…åº”ç”¨: åŠ¨æ€å‚æ•°æ›¿æ¢ç¤ºä¾‹ã€‘")
    info("=" * 80)
    
    # æ¨¡æ‹Ÿç”¨æˆ·ä¿®æ”¹å‚æ•°
    new_values = {
        "years_0": "10å¹´",       # åŸ "5å¹´ç»éªŒ" ä¸­çš„å¹´ä»½
        "weeks_1": "6å‘¨",        # åŸ "3å‘¨"
        "people_2": "15äºº",      # åŸ "8äºº"
    }
    
    info("\nå‡è®¾ç”¨æˆ·æƒ³ä¿®æ”¹ä»¥ä¸‹å‚æ•°:")
    for var_name, new_val in new_values.items():
        for var in variable_metas:
            if var.name == var_name:
                info(f"  â€¢ {var.original_text} â†’ {new_val}")
    
    customized = template
    for var_name, new_val in new_values.items():
        placeholder = f"{{{{{var_name}}}}}"
        if placeholder in customized:
            customized = customized.replace(placeholder, new_val)
    
    # å¡«å……æœªä¿®æ”¹çš„å˜é‡
    for var in variable_metas:
        placeholder = f"{{{{{var.name}}}}}"
        if placeholder in customized:
            customized = customized.replace(placeholder, var.original_text)
    
    info("\nã€å®šåˆ¶åçš„æ–‡æœ¬ã€‘")
    info("â”€" * 80)
    info(customized)
    
    info("\n" + "=" * 80)
    info("ã€æ¼”ç¤ºå®Œæˆã€‘")
    info("=" * 80)


if __name__ == "__main__":
    demo_complex_extraction()
