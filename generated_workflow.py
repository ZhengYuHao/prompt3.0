"""
Auto-generated by WaAct Compiler
DO NOT EDIT THIS FILE MANUALLY
"""

from typing import Dict, Any
from llm_client import invoke_function  # 需要实现 LLM 客户端


def step_1_compute_knowledge_base_a(vector_index_a, vector_index_b, vector_index_c):
    """Auto-generated module"""
    return alert_duration, cache_ttl, code_line_limit, fallback_results, kg_hop, knowledge_base_a, knowledge_base_b, knowledge_base_c, log_retention_access, log_retention_debug, log_retention_error, max_concurrent, max_results, qps_threshold, re_rank_results, response_time_threshold, similarity_threshold, vector_dim


async def step_2_vector_search(cache_ttl, code_line_limit, kg_hop, max_results, query_type, re_rank_results, similarity_threshold):
    """Auto-generated module"""
    if query_type == "simple_fact":
        results = await invoke_function('vector_search', query=query, similarity_threshold=similarity_threshold)
        if results.similarity >= similarity_threshold:
            top_results = results.top_n(max_results)
            return top_results
        elif results.similarity < similarity_threshold:
            re_ranked = await invoke_function('re_rank', results=results, top_n=re_rank_results)
            return re_ranked
        else:
            hybrid_results = await invoke_function('hybrid_search', query=query)
            return hybrid_results
    elif query_type == "complex_reasoning":
        intent = await invoke_function('intent_analysis', query=query)
        kg_results = await invoke_function('kg_search', intent=intent, hops=kg_hop)
        if kg_results.found:
            entities = kg_results.entities
            relations = kg_results.relations
            return entities, relations
        else:
            full_search = await invoke_function('full_search', query=query)
            return full_search
        cache.store(query, kg_results, ttl=cache_ttl)
    elif query_type == "code_analysis":
        language = await invoke_function('detect_language', query=query)
        line_count = await invoke_function('count_lines', query=query)
        if language  in  ["Python", "Java"]:
            if line_count > code_line_limit:
                static_analysis = await invoke_function('static_analysis', query=query)
                return static_analysis
            else:
                semantic_analysis = await invoke_function('semantic_analysis', query=query)
                doc = await invoke_function('generate_doc', semantic_analysis=semantic_analysis)
                return doc
        else:
            return "Unsupported language"
    else:
        return "Unknown query type"


async def step_3_use_stronger_model(user_feedback):
    """Auto-generated module"""
    if user_feedback == "regenerate":
        stronger_model = await invoke_function('use_stronger_model')
        return stronger_model


async def step_4_escalate_to_human_review(negative_feedback_count):
    """Auto-generated module"""
    if negative_feedback_count >= 3:
        await invoke_function('escalate_to_human_review')
    return None


async def step_5_verify_user(query):
    """Auto-generated module"""
    if "金融" in query  or  "财务"  or  "投资":
        verified = await invoke_function('verify_user')
        if  not  verified:
            await invoke_function('log_to_security')
            return "Access denied"


async def step_6_trigger_alert(alert_duration, qps, qps_threshold):
    """Auto-generated module"""
    if qps < qps_threshold:
        await invoke_function('trigger_alert')
    return None


async def step_7_create_log(query, response):
    """Auto-generated module"""
    log = await invoke_function('create_log', query=query, response=response)
    return log


async def step_8_upload_to_central_logging(log):
    """Auto-generated module"""
    await invoke_function('upload_to_central_logging', log=log)
    return None


async def main_workflow(input_params: dict):
    """
    主工作流 - 自动生成
    
    Args:
        input_params: 包含 ['negative_feedback_count', 'qps', 'query_type', 'response', 'user_feedback', 'vector_index_a', 'vector_index_b', 'vector_index_c'] 的字典
    
    Returns:
        执行结果上下文
    """
    # 初始化上下文
    ctx = input_params.copy()

    # Module 1: step_1_compute_knowledge_base_a
    ctx["alert_duration"], ctx["cache_ttl"], ctx["code_line_limit"], ctx["fallback_results"], ctx["kg_hop"], ctx["knowledge_base_a"], ctx["knowledge_base_b"], ctx["knowledge_base_c"], ctx["log_retention_access"], ctx["log_retention_debug"], ctx["log_retention_error"], ctx["max_concurrent"], ctx["max_results"], ctx["qps_threshold"], ctx["re_rank_results"], ctx["response_time_threshold"], ctx["similarity_threshold"], ctx["vector_dim"] = step_1_compute_knowledge_base_a(ctx.get("vector_index_a"), ctx.get("vector_index_b"), ctx.get("vector_index_c"))

    # Module 2: step_2_vector_search
    ctx["__doc__"], ctx["__full_search__"], ctx["__hybrid_results__"], ctx["__re_ranked__"], ctx["__static_analysis__"], ctx["__top_results__"], ctx["cache"], ctx["doc"], ctx["entities"], ctx["full_search"], ctx["hybrid_results"], ctx["intent"], ctx["kg_results"], ctx["language"], ctx["line_count"], ctx["query"], ctx["re_ranked"], ctx["relations"], ctx["results"], ctx["semantic_analysis"], ctx["static_analysis"], ctx["top_results"] = await step_2_vector_search(ctx.get("cache_ttl"), ctx.get("code_line_limit"), ctx.get("kg_hop"), ctx.get("max_results"), ctx.get("query_type"), ctx.get("re_rank_results"), ctx.get("similarity_threshold"))

    # Module 3: step_3_use_stronger_model
    ctx["__stronger_model__"], ctx["stronger_model"] = await step_3_use_stronger_model(ctx.get("user_feedback"))

    # Module 4: step_4_escalate_to_human_review
    await step_4_escalate_to_human_review(ctx.get("negative_feedback_count"))

    # Module 5: step_5_verify_user
    ctx["verified"] = await step_5_verify_user(ctx.get("query"))

    # Module 6: step_6_trigger_alert
    await step_6_trigger_alert(ctx.get("alert_duration"), ctx.get("qps"), ctx.get("qps_threshold"))

    # Module 7: step_7_create_log
    ctx["log"] = await step_7_create_log(ctx.get("query"), ctx.get("response"))

    # Module 8: step_8_upload_to_central_logging
    await step_8_upload_to_central_logging(ctx.get("log"))

    return ctx



if __name__ == "__main__":
    import asyncio
    
    # 测试输入
    test_input = {
        # TODO: 填充实际参数
    }
    
    result = asyncio.run(main_workflow(test_input))
    from logger import info
    info("执行结果:", result)