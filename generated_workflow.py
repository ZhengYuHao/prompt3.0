"""
Auto-generated by WaAct Compiler
DO NOT EDIT THIS FILE MANUALLY
"""

from typing import Dict, Any
from llm_client import invoke_function  # 需要实现 LLM 客户端


def step_1_compute_cache_duration(cache_hit_rate, click_feedback, code_lines, current_concurrent, is_admin, is_finance, is_sensitive, is_vip, knowledge_base, priority, qps, query_type, response_time, search_accuracy, similarity, unhappy_count, user_level, vector_index, vi_a, vi_b, vi_c):
    """Auto-generated module"""
    return alert_duration, alert_qps_threshold, cache_duration, code_time_threshold, fallback_vector_results, graph_time_threshold, kb_a_docs, kb_b_docs, kb_c_docs, kg_hops, log_access_days, log_debug_days, log_error_days, max_code_lines, max_concurrent, max_vector_results, response_time_threshold, timeout_threshold, vector_dim, vector_time_threshold


async def step_2_vector_search(cache_duration, code, code_lines, fallback_vector_results, kg_hops, knowledge_base, max_code_lines, max_vector_results, query_type, similarity):
    """Auto-generated module"""
    if query_type == "simple_fact":
        if similarity > 0.85:
            result = await invoke_function('vector_search', knowledge_base=knowledge_base, top_n=max_vector_results)
        elif similarity <= 0.85:
            result = await invoke_function('rerank_search', knowledge_base=knowledge_base, top_n=fallback_vector_results)
        else:
            result = await invoke_function('hybrid_search', knowledge_base=knowledge_base)
    elif query_type == "complex_reasoning":
        result = await invoke_function('graph_search', knowledge_base=knowledge_base, hops=kg_hops)
        if result.found == False:
            result = await invoke_function('full_search', knowledge_base=knowledge_base)
        result.cache_duration = cache_duration
        await invoke_function('cache_result', result=result)
    elif query_type == "code_analysis":
        if code_lines > max_code_lines:
            result = await invoke_function('static_code_analysis', code=code)
        else:
            result = await invoke_function('semantic_code_analysis', code=code)
            result = await invoke_function('generate_code_explanation', result=result)
    else:
        result = await invoke_function('default_search', knowledge_base=knowledge_base)
    return result


async def step_3_strong_model_inference(click_feedback, query, unhappy_count):
    """Auto-generated module"""
    if click_feedback == "regenerate":
        result = await invoke_function('strong_model_inference', query=query)
    elif unhappy_count >= 3:
        result = await invoke_function('human_review', query=query)
    return result


async def step_4_reject_service(is_finance, is_sensitive, query):
    """Auto-generated module"""
    if is_sensitive == True:
        await invoke_function('reject_service')
        await invoke_function('log_sensitive_content', query=query)
    elif is_finance == True:
        result = await invoke_function('identity_verification')
        if result.verified == False:
            await invoke_function('reject_service')
    return result


async def step_5_queue_request(current_concurrent, is_admin, is_vip, max_concurrent):
    """Auto-generated module"""
    if current_concurrent > max_concurrent:
        await invoke_function('queue_request')
        if is_vip == True:
            priority = 5
        elif is_admin == True:
            priority = 10
        else:
            priority = 1
    return priority


async def step_6_degraded_service(response_time, timeout_threshold):
    """Auto-generated module"""
    if response_time > timeout_threshold:
        result = await invoke_function('degraded_service')
    return result


async def step_7_log_performance(code_time_threshold, graph_time_threshold, query_type, response_time, vector_time_threshold):
    """Auto-generated module"""
    if response_time > vector_time_threshold  and  query_type == "simple_fact":
        await invoke_function('log_performance', _vector_search_=_vector_search_, response_time=response_time)
    elif response_time > graph_time_threshold  and  query_type == "complex_reasoning":
        await invoke_function('log_performance', _graph_search_=_graph_search_, response_time=response_time)
    elif response_time > code_time_threshold  and  query_type == "code_analysis":
        await invoke_function('log_performance', _code_analysis_=_code_analysis_, response_time=response_time)
    return None


async def step_8_trigger_alert(alert_duration, alert_qps_threshold, qps):
    """Auto-generated module"""
    if qps < alert_qps_threshold:
        await invoke_function('trigger_alert', _low_qps_=_low_qps_)
    return None


async def step_9_scale_out(response_time, response_time_threshold):
    """Auto-generated module"""
    if response_time > response_time_threshold:
        await invoke_function('scale_out')
    return None


def step_10_compute_result(result):
    """Auto-generated module"""
    return result


async def main_workflow(input_params: dict):
    """
    主工作流 - 自动生成
    
    Args:
        input_params: 包含 ['cache_hit_rate', 'click_feedback', 'code', 'code_lines', 'current_concurrent', 'is_admin', 'is_finance', 'is_sensitive', 'is_vip', 'knowledge_base', 'qps', 'query', 'query_type', 'response_time', 'search_accuracy', 'similarity', 'unhappy_count', 'user_level', 'vector_index', 'vi_a', 'vi_b', 'vi_c'] 的字典
    
    Returns:
        执行结果上下文
    """
    # 初始化上下文
    ctx = input_params.copy()

    # Module 1: step_1_compute_cache_duration
    ctx["alert_duration"], ctx["alert_qps_threshold"], ctx["cache_duration"], ctx["code_time_threshold"], ctx["fallback_vector_results"], ctx["graph_time_threshold"], ctx["kb_a_docs"], ctx["kb_b_docs"], ctx["kb_c_docs"], ctx["kg_hops"], ctx["log_access_days"], ctx["log_debug_days"], ctx["log_error_days"], ctx["max_code_lines"], ctx["max_concurrent"], ctx["max_vector_results"], ctx["response_time_threshold"], ctx["timeout_threshold"], ctx["vector_dim"], ctx["vector_time_threshold"] = step_1_compute_cache_duration(ctx.get("cache_hit_rate"), ctx.get("click_feedback"), ctx.get("code_lines"), ctx.get("current_concurrent"), ctx.get("is_admin"), ctx.get("is_finance"), ctx.get("is_sensitive"), ctx.get("is_vip"), ctx.get("knowledge_base"), ctx.get("priority"), ctx.get("qps"), ctx.get("query_type"), ctx.get("response_time"), ctx.get("search_accuracy"), ctx.get("similarity"), ctx.get("unhappy_count"), ctx.get("user_level"), ctx.get("vector_index"), ctx.get("vi_a"), ctx.get("vi_b"), ctx.get("vi_c"))

    # Module 2: step_2_vector_search
    ctx["result"] = await step_2_vector_search(ctx.get("cache_duration"), ctx.get("code"), ctx.get("code_lines"), ctx.get("fallback_vector_results"), ctx.get("kg_hops"), ctx.get("knowledge_base"), ctx.get("max_code_lines"), ctx.get("max_vector_results"), ctx.get("query_type"), ctx.get("similarity"))

    # Module 3: step_3_strong_model_inference
    ctx["result"] = await step_3_strong_model_inference(ctx.get("click_feedback"), ctx.get("query"), ctx.get("unhappy_count"))

    # Module 4: step_4_reject_service
    ctx["result"] = await step_4_reject_service(ctx.get("is_finance"), ctx.get("is_sensitive"), ctx.get("query"))

    # Module 5: step_5_queue_request
    ctx["priority"] = await step_5_queue_request(ctx.get("current_concurrent"), ctx.get("is_admin"), ctx.get("is_vip"), ctx.get("max_concurrent"))

    # Module 6: step_6_degraded_service
    ctx["result"] = await step_6_degraded_service(ctx.get("response_time"), ctx.get("timeout_threshold"))

    # Module 7: step_7_log_performance
    await step_7_log_performance(ctx.get("code_time_threshold"), ctx.get("graph_time_threshold"), ctx.get("query_type"), ctx.get("response_time"), ctx.get("vector_time_threshold"))

    # Module 8: step_8_trigger_alert
    await step_8_trigger_alert(ctx.get("alert_duration"), ctx.get("alert_qps_threshold"), ctx.get("qps"))

    # Module 9: step_9_scale_out
    await step_9_scale_out(ctx.get("response_time"), ctx.get("response_time_threshold"))

    # Module 10: step_10_compute_result
    ctx["__result__"] = step_10_compute_result(ctx.get("result"))

    return ctx



if __name__ == "__main__":
    import asyncio
    
    # 测试输入
    test_input = {
        # TODO: 填充实际参数
    }
    
    result = asyncio.run(main_workflow(test_input))
    from logger import info
    info("执行结果:", result)