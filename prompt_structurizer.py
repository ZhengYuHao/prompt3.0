"""
S.E.D.E Framework - Step 2: å®ä½“æŠ½å–ä¸å˜é‡å®šä¹‰ (Entity Extraction & Variable Definition)
å……å½“ç¼–è¯‘å™¨å‰ç«¯çš„è¯æ³•åˆ†æè§’è‰²,å°†è‡ªç„¶è¯­è¨€ä¸­çš„å¸¸é‡ä¸å˜é‡åˆ†ç¦»
ç‰ˆæœ¬: 2.0
"""

import json
import re
import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from collections import defaultdict
from logger import info, warning, error, debug, setup_logger
from llm_client import UnifiedLLMClient, create_llm_client
from data_models import (
    DataType, VariableMeta, Prompt10Result, Prompt20Result,
    create_prompt20_result, generate_id, get_timestamp
)
from history_manager import HistoryManager, Prompt20History

# ========== é…ç½®æ—¥å¿—ç³»ç»Ÿ ==========
logger = setup_logger("prompt3.0.step2")


# ========== å…¼å®¹æ€§æ•°æ®ç»“æ„ï¼ˆä¿ç•™æ—§æ¥å£ï¼‰ ==========
@dataclass
class VariableConstraints:
    """å˜é‡çº¦æŸæ¡ä»¶"""
    min_value: Optional[int] = None
    max_value: Optional[int] = None
    allowed_values: Optional[List[str]] = None
    pattern: Optional[str] = None


@dataclass
class PromptStructure:
    """Prompt 2.0 ç»“æ„åŒ–è¾“å‡ºï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
    template_text: str  # å¸¦ {{variable}} å ä½ç¬¦çš„æ¨¡æ¿
    variable_registry: List[Dict]  # å˜é‡æ³¨å†Œè¡¨
    original_text: str  # åŸå§‹æ–‡æœ¬
    extraction_log: List[str]  # æå–æ—¥å¿—


# ========== LLM å®ä½“æå–å™¨ ==========
class LLMEntityExtractor:
    """LLM å®ä½“æå–æ¥å£ (è¯­ä¹‰æ‰«æå±‚) - ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯"""
    
    def __init__(
        self,
        llm_client: Optional[UnifiedLLMClient] = None,
        use_mock: bool = False
    ):
        """
        åˆå§‹åŒ–å®ä½“æå–å™¨
        
        Args:
            llm_client: ç»Ÿä¸€LLMå®¢æˆ·ç«¯å®ä¾‹
            use_mock: æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        """
        self.llm = llm_client or create_llm_client(use_mock=use_mock)
        self.use_mock = use_mock

    def extract(self, text: str) -> List[Dict]:
        """
        è°ƒç”¨ LLM è¿›è¡Œå®ä½“æå–
        
        Args:
            text: å¾…æŠ½å–æ–‡æœ¬
            
        Returns:
            å®ä½“åˆ—è¡¨
        """
        if self.use_mock:
            return self._mock_extract(text)
        
        # ä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯çš„å®ä½“æŠ½å–åŠŸèƒ½
        return self.llm.extract_entities(text)
    
    def _mock_extract(self, text: str) -> List[Dict]:
        """æ¨¡æ‹Ÿå®ä½“æŠ½å–ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        mock_entities = []
        
        # è¯†åˆ«æ•°å­—+å•ä½æ¨¡å¼ (å¦‚ "3å¹´", "2å‘¨")
        for match in re.finditer(r'(\d+)(å¹´|å‘¨|æœˆ|å¤©|å°æ—¶|åˆ†é’Ÿ)', text):
            mock_entities.append({
                "name": f"duration_{match.group(2)}",
                "original_text": match.group(0),
                "start_index": match.start(),
                "end_index": match.end(),
                "type": "Integer",
                "value": int(match.group(1))
            })
        
        # è¯†åˆ«ä¸“ä¸šæœ¯è¯­
        tech_terms = ["Javaç¨‹åºå‘˜", "Python", "æ•°æ®åˆ†æ", "æœºå™¨å­¦ä¹ ", "å‰ç«¯å¼€å‘"]
        for term in tech_terms:
            if term in text:
                idx = text.find(term)
                mock_entities.append({
                    "name": f"tech_term_{len(mock_entities)}",
                    "original_text": term,
                    "start_index": idx,
                    "end_index": idx + len(term),
                    "type": "String",
                    "value": term
                })
        
        return mock_entities


# ========== å¹»è§‰é˜²ç«å¢™ ==========
class HallucinationFirewall:
    """é˜²æ­¢ LLM è™šæ„åŸæ–‡ä¸­ä¸å­˜åœ¨çš„å†…å®¹"""
    
    @staticmethod
    def validate_existence(entity: Dict, original_text: str) -> Tuple[bool, str]:
        """
        å­˜åœ¨æ€§æ ¡éªŒ: ç¡®ä¿ LLM æå–çš„ç‰‡æ®µçœŸå®å­˜åœ¨äºåŸæ–‡
        """
        original_snippet = entity.get('original_text', '')
        
        # ç²¾ç¡®åŒ¹é…
        if original_snippet in original_text:
            return True, "ç²¾ç¡®åŒ¹é…é€šè¿‡"
        
        # æ¨¡ç³ŠåŒ¹é… (å¤„ç†ç©ºæ ¼ã€æ ‡ç‚¹å·®å¼‚)
        normalized_snippet = re.sub(r'\s+', '', original_snippet)
        normalized_text = re.sub(r'\s+', '', original_text)
        
        if normalized_snippet in normalized_text:
            return True, "æ¨¡ç³ŠåŒ¹é…é€šè¿‡"
        
        return False, f"å¹»è§‰æ£€æµ‹: '{original_snippet}' ä¸å­˜åœ¨äºåŸæ–‡"
    
    @staticmethod
    def validate_index(entity: Dict, original_text: str) -> bool:
        """éªŒè¯ç´¢å¼•ä½ç½®çš„å‡†ç¡®æ€§"""
        start = entity.get('start_index', -1)
        end = entity.get('end_index', -1)
        original_snippet = entity.get('original_text', '')
        
        if start == -1 or end == -1:
            return False
        
        if start < 0 or end > len(original_text) or start >= end:
            return False
        
        extracted = original_text[start:end]
        return extracted == original_snippet


# ========== å®ä½“åå¤„ç†æ ¡éªŒå™¨ ==========
class EntityPostValidator:
    """åå¤„ç†å®ä½“æ ¡éªŒå™¨ - è¿‡æ»¤æ‰å›ºå®šæè¿°è€Œéå˜é‡çš„å®ä½“"""
    
    # å›ºå®šæè¿°å…³é”®è¯ï¼ˆåŒ…å«è¿™äº›è¯ä¸”æ²¡æœ‰æ•°å­—çš„å¯èƒ½æ˜¯å›ºå®šéœ€æ±‚ï¼‰
    FIXED_DESCRIPTION_KEYWORDS = ["éœ€è¦", "è¦", "æ”¯æŒ", "ç¡®ä¿", "å®ç°", "æä¾›", "ç”¨", "é‡‡ç”¨"]
    
    # å¸¸è§å›ºå®šéœ€æ±‚æ¨¡å¼ï¼ˆæ•´ä½“ä¸æå–ä¸ºå˜é‡ï¼‰
    FIXED_DEMAND_PATTERNS = [
        r"éœ€è¦æ”¯æŒ.*å¯¹è¯",  # "éœ€è¦æ”¯æŒå¤šè½®å¯¹è¯"
        r"æ”¯æŒ.*åŒè¯­",  # "æ”¯æŒä¸­è‹±æ–‡åŒè¯­"
        r"ç”¨.*åšåº•åº§",  # "ç”¨å¤§æ¨¡å‹åšåº•åº§"
        r"å“åº”æ—¶é—´æ§åˆ¶åœ¨.*ä»¥å†…",  # æ•´ä½“ä¸ºé…ç½®æè¿°
        r"ä¸Šä¸‹æ–‡çª—å£å­˜.*è½®",  # æœ‰æ•°å­—ä½†è¦å•ç‹¬æå–
        r"ç”¨LangChain.*Milvus.*FastAPI",  # æŠ€æœ¯æ ˆæ•´ä½“æå–
    ]
    
    # å˜é‡å…³é”®è¯ï¼ˆè¡¨æ˜æ˜¯å¯é…ç½®å‚æ•°ï¼‰
    VARIABLE_KEYWORDS = ["ä¸ª", "äºº", "ä¸‡", "å¹´", "å‘¨", "æœˆ", "å¤©", "è½®", "ç§’", "å°æ—¶", "åˆ†é’Ÿ"]
    
    @classmethod
    def filter_entities(cls, entities: List[Dict], original_text: str) -> Tuple[List[Dict], List[str]]:
        """
        è¿‡æ»¤æ‰å›ºå®šæè¿°è€Œéå˜é‡çš„å®ä½“
        
        Returns:
            (è¿‡æ»¤åçš„å®ä½“åˆ—è¡¨, è¿‡æ»¤æ—¥å¿—åˆ—è¡¨)
        """
        filtered = []
        filter_logs = []
        
        for entity in entities:
            orig_text = entity.get('original_text', '')
            entity_name = entity.get('name', '')
            filter_reason = cls._should_filter(orig_text, entity_name)
            
            if filter_reason:
                filter_logs.append(f"è¿‡æ»¤: '{orig_text}' - {filter_reason}")
                continue
            
            filtered.append(entity)
        
        return filtered, filter_logs
    
    @classmethod
    def _should_filter(cls, text: str, entity_name: str) -> Optional[str]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿‡æ»¤è¯¥å®ä½“ï¼Œè¿”å›è¿‡æ»¤åŸå› æˆ– None"""
        # è§„åˆ™1: åŒ…å«å›ºå®šæè¿°å…³é”®è¯ä½†æ²¡æœ‰æ•°å­— -> å¯èƒ½æ˜¯å›ºå®šéœ€æ±‚
        if any(kw in text for kw in cls.FIXED_DESCRIPTION_KEYWORDS):
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å­—
            if not re.search(r'\d+', text):
                # ç‰¹æ®Šæƒ…å†µï¼šæŠ€æœ¯æ ˆåˆ—è¡¨ï¼ˆå¦‚ "LangChainã€Milvusã€FastAPI"ï¼‰
                if not cls._is_tech_stack(text):
                    return "åŒ…å«éœ€æ±‚æè¿°å…³é”®è¯ä½†æ— æ•°å­—ï¼Œå¯èƒ½æ˜¯å›ºå®šéœ€æ±‚"
        
        # è§„åˆ™2: æ˜ç¡®çš„å›ºå®šéœ€æ±‚æè¿°ï¼ˆå³ä½¿æœ‰æ•°å­—ä¹Ÿè¦è¿‡æ»¤ï¼‰
        # "éœ€è¦æ”¯æŒå¤šè½®å¯¹è¯" - æ•´ä½“æè¿°
        if text in ["éœ€è¦æ”¯æŒå¤šè½®å¯¹è¯", "éœ€è¦ä¸­è‹±æ–‡åŒè¯­", "ç”¨å¤§æ¨¡å‹åšåº•åº§"]:
            return "æ˜ç¡®çš„å›ºå®šéœ€æ±‚æè¿°"
        
        # "å“åº”æ—¶é—´æ§åˆ¶åœ¨2ç§’ä»¥å†…" - é…ç½®æè¿°ï¼Œåº”åªæå– "2ç§’"
        if "å“åº”æ—¶é—´æ§åˆ¶" in text:
            return "é…ç½®æè¿°ï¼Œåº”åªæå–æ•°å€¼éƒ¨åˆ†"
        
        # è§„åˆ™3: ç»†åˆ†å˜é‡ï¼ˆå¦‚ "java_developers"ï¼‰-> å¦‚æœåŸæ–‡æœ‰æ€»äººæ•°ï¼Œåªä¿ç•™æ€»äººæ•°
        if re.search(r'(java|python|frontend|backend).*developers?', entity_name, re.IGNORECASE):
            return "ç»†åˆ†å˜é‡ï¼Œå»ºè®®åˆå¹¶ä¸ºå›¢é˜Ÿæ€»äººæ•°"
        
        # è§„åˆ™4: æ£€æŸ¥æ˜¯å¦åŒ…å«å˜é‡å…³é”®è¯
        has_variable_keyword = any(kw in text for kw in cls.VARIABLE_KEYWORDS)
        if not has_variable_keyword:
            # æ²¡æœ‰å˜é‡å…³é”®è¯çš„å¯èƒ½æ˜¯å›ºå®šæè¿°
            # ä½†æŠ€æœ¯æ ˆã€ä¸“æœ‰åè¯ä¾‹å¤–
            if not cls._is_tech_stack(text) and not cls._is_proper_noun(text):
                return "ä¸åŒ…å«å˜é‡å…³é”®è¯ï¼Œå¯èƒ½æ˜¯å›ºå®šæè¿°"
        
        return None
    
    @classmethod
    def _is_tech_stack(cls, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæŠ€æœ¯æ ˆåˆ—è¡¨"""
        tech_indicators = ["LangChain", "Milvus", "FastAPI", "K8s", "Kubernetes", "ELK", "Prometheus", "Grafana"]
        return any(tech in text for tech in tech_indicators) and "ã€" in text
    
    @classmethod
    def _is_proper_noun(cls, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºä¸“æœ‰åè¯ï¼ˆæŠ€æœ¯æœ¯è¯­ï¼‰"""
        proper_nouns = [
            # æŠ€æœ¯æ¡†æ¶/å¹³å°
            "RAG", "LLM", "API", "K8s", "Kubernetes",
            "LangChain", "Milvus", "FastAPI",
            # ç¼–ç¨‹è¯­è¨€
            "Python", "Java", "JavaScript", "TypeScript",
            "C++", "C#", "Go", "Rust", "PHP", "Ruby",
            # æ•°æ®ç§‘å­¦/æœºå™¨å­¦ä¹ 
            "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "æ•°æ®åˆ†æ", "äººå·¥æ™ºèƒ½",
            "AI", "ML", "DL", "TensorFlow", "PyTorch",
            # æ•°æ®åº“/å­˜å‚¨
            "MySQL", "PostgreSQL", "MongoDB", "Redis",
            "Elasticsearch", "Milvus", "å‘é‡æ•°æ®åº“",
            # å¼€å‘é¢†åŸŸ
            "å‰ç«¯å¼€å‘", "åç«¯å¼€å‘", "å…¨æ ˆå¼€å‘",
            "Webå¼€å‘", "ç§»åŠ¨å¼€å‘", "æ•°æ®ç§‘å­¦",
            # å…¶ä»–æŠ€æœ¯æœ¯è¯­
            "å¾®æœåŠ¡", "å®¹å™¨åŒ–", "DevOps", "CI/CD"
        ]
        return any(noun in text for noun in proper_nouns)
    
    @staticmethod
    def merge_duplicate_entities(entities: List[Dict]) -> List[Dict]:
        """
        åˆå¹¶é‡å¤æˆ–é‡å çš„å®ä½“
        
        ä¾‹å¦‚ï¼š
        - "5ä¸ªäºº" å’Œ "5" â†’ ä¿ç•™ "5ä¸ªäºº"
        - "8å‘¨" å’Œ "å‘¨" â†’ ä¿ç•™ "8å‘¨"
        """
        if not entities:
            return []
        
        merged = []
        processed_indices = set()
        
        for i, entity1 in enumerate(entities):
            if i in processed_indices:
                continue
            
            orig_text1 = entity1.get('original_text', '')
            
            # æŸ¥æ‰¾æ˜¯å¦æœ‰å…¶ä»–å®ä½“åŒ…å«å½“å‰å®ä½“
            for j, entity2 in enumerate(entities):
                if i >= j or j in processed_indices:
                    continue
                
                orig_text2 = entity2.get('original_text', '')
                
                # å¦‚æœ entity1 åŒ…å« entity2ï¼Œä¿ç•™ entity1ï¼ˆæ›´é•¿çš„ï¼‰
                if orig_text2 in orig_text1:
                    processed_indices.add(j)
                    logger.info(f"åˆå¹¶å®ä½“: '{orig_text2}' â†’ '{orig_text1}'")
            
            merged.append(entity1)
            processed_indices.add(i)
        
        return merged


# ========== å¼ºç±»å‹æ¸…æ´—å™¨ ==========
class TypeCleaner:
    """å¼ºç±»å‹æ¸…æ´—ä¸è½¬æ¢ (Code-Layer)"""
    
    # Boolean å½’ä¸€åŒ–æ˜ å°„è¡¨
    BOOLEAN_MAP = {
        'æ˜¯': True, 'è¦': True, 'éœ€è¦': True, 'å¯¹': True, 'yes': True, 'true': True, '1': True,
        'å¦': False, 'ä¸': False, 'ä¸è¦': False, 'é”™': False, 'no': False, 'false': False, '0': False
    }
    
    @classmethod
    def clean(cls, value: Any, target_type: str) -> Tuple[Any, str]:
        """
        ç±»å‹æ¸…æ´—ä¸è½¬æ¢
        è¿”å›: (è½¬æ¢åçš„å€¼, å®é™…ç±»å‹)
        """
        try:
            if target_type == DataType.INTEGER.value:
                return cls._clean_integer(value)
            
            elif target_type == DataType.BOOLEAN.value:
                return cls._clean_boolean(value)
            
            elif target_type == DataType.LIST.value:
                return cls._clean_list(value)
            
            elif target_type == DataType.ENUM.value:
                return cls._clean_enum(value)
            
            else:  # String (é»˜è®¤)
                return str(value), DataType.STRING.value
                
        except Exception as e:
            logger.warning(f"ç±»å‹è½¬æ¢å¤±è´¥: {value} -> {target_type}, é”™è¯¯: {e}, é™çº§ä¸º String")
            return str(value), DataType.STRING.value
    
    @staticmethod
    def _clean_integer(value: Any) -> Tuple[int, str]:
        """Integer æ¸…æ´—"""
        if isinstance(value, int):
            return value, DataType.INTEGER.value
        
        # ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
        if isinstance(value, str):
            numbers = re.findall(r'-?\d+', value)
            if numbers:
                return int(numbers[0]), DataType.INTEGER.value
        
        raise ValueError(f"æ— æ³•è§£æä¸ºæ•´æ•°: {value}")
    
    @classmethod
    def _clean_boolean(cls, value: Any) -> Tuple[bool, str]:
        """Boolean æ¸…æ´—"""
        if isinstance(value, bool):
            return value, DataType.BOOLEAN.value
        
        str_value = str(value).strip().lower()
        if str_value in cls.BOOLEAN_MAP:
            return cls.BOOLEAN_MAP[str_value], DataType.BOOLEAN.value
        
        raise ValueError(f"æ— æ³•è§£æä¸ºå¸ƒå°”å€¼: {value}")
    
    @staticmethod
    def _clean_list(value: Any) -> Tuple[List, str]:
        """List æ¸…æ´— - æ£€æµ‹é€—å·ã€é¡¿å·åˆ†éš”ç¬¦"""
        if isinstance(value, list):
            return value, DataType.LIST.value
        
        if isinstance(value, str):
            # å°è¯•å¤šç§åˆ†éš”ç¬¦
            for separator in [',', 'ã€', 'ï¼Œ', ';', 'ï¼›']:
                if separator in value:
                    items = [item.strip() for item in value.split(separator)]
                    return items, DataType.LIST.value
            
            # å•å…ƒç´ åˆ—è¡¨
            return [value], DataType.LIST.value
        
        return [str(value)], DataType.LIST.value
    
    @staticmethod
    def _clean_enum(value: Any) -> Tuple[str, str]:
        """Enum æ¸…æ´—"""
        return str(value), DataType.ENUM.value


# ========== å®ä½“å†²çªè§£æå™¨ ==========
class EntityConflictResolver:
    """å¤„ç†é‡å å®ä½“ (Overlapping Entities)"""
    
    @staticmethod
    def resolve_overlaps(entities: List[Dict]) -> List[Dict]:
        """
        æœ€é•¿è¦†ç›–åŸåˆ™: ä¼˜å…ˆä¿ç•™æ›´é•¿çš„å®ä½“
        ä¾‹: "3å¹´ç»éªŒ" vs "3å¹´", ä¿ç•™ "3å¹´ç»éªŒ"
        """
        if not entities:
            return []
        
        # æŒ‰èµ·å§‹ä½ç½®æ’åº
        sorted_entities = sorted(entities, key=lambda x: (x['start_index'], -(x['end_index'] - x['start_index'])))
        
        non_overlapping = []
        last_end = -1
        
        for entity in sorted_entities:
            start = entity['start_index']
            end = entity['end_index']
            
            # å¦‚æœå½“å‰å®ä½“ä¸ä¸Šä¸€ä¸ªä¸é‡å 
            if start >= last_end:
                non_overlapping.append(entity)
                last_end = end
            else:
                # å‘ç”Ÿé‡å ,æ¯”è¾ƒé•¿åº¦
                if len(non_overlapping) > 0:
                    last_entity = non_overlapping[-1]
                    current_length = end - start
                    last_length = last_entity['end_index'] - last_entity['start_index']
                    
                    if current_length > last_length:
                        # æ›¿æ¢ä¸ºæ›´é•¿çš„å®ä½“
                        non_overlapping[-1] = entity
                        last_end = end
        
        return non_overlapping


# ========== æ ¸å¿ƒå¤„ç†å¼•æ“ ==========
class PromptStructurizer:
    """Prompt ç»“æ„åŒ–å¤„ç†å¼•æ“ (ä¸»æ§åˆ¶å™¨)"""
    
    def __init__(
        self,
        llm_client: Optional[UnifiedLLMClient] = None,
        use_mock: bool = False
    ):
        """
        åˆå§‹åŒ–ç»“æ„åŒ–å¤„ç†å¼•æ“
        
        Args:
            llm_client: ç»Ÿä¸€LLMå®¢æˆ·ç«¯å®ä¾‹
            use_mock: æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        """
        self.llm_extractor = LLMEntityExtractor(
            llm_client=llm_client,
            use_mock=use_mock
        )
        self.firewall = HallucinationFirewall()
        self.type_cleaner = TypeCleaner()
        self.conflict_resolver = EntityConflictResolver()
        self.entity_validator = EntityPostValidator()  # æ–°å¢ï¼šåå¤„ç†æ ¡éªŒå™¨
        self.extraction_log = []
        self.use_mock = use_mock
        self.history_manager = HistoryManager()
    
    def process_from_prompt10(
        self, 
        prompt10_result: Prompt10Result,
        save_history: bool = True
    ) -> Prompt20Result:
        """
        ä» Prompt 1.0 ç»“æœè¿›è¡Œå¤„ç†
        
        Args:
            prompt10_result: Prompt 1.0 çš„å¤„ç†ç»“æœ
            save_history: æ˜¯å¦ä¿å­˜å†å²è®°å½•
            
        Returns:
            Prompt20Result: Prompt 2.0 ç»“æ„åŒ–ç»“æœ
        """
        start_time = time.time()
        
        # ä½¿ç”¨ Prompt 1.0 çš„å¤„ç†åæ–‡æœ¬
        clean_text = prompt10_result.processed_text
        
        # è°ƒç”¨æ ¸å¿ƒå¤„ç†æµç¨‹
        structure = self.process(clean_text)
        
        # æ„å»º VariableMeta åˆ—è¡¨
        variables = [
            VariableMeta(
                name=reg["variable"],
                original_text=reg["original_text"],
                value=reg["value"],
                data_type=reg["type"],
                start_index=0,  # ç®€åŒ–å¤„ç†
                end_index=len(reg["original_text"]),
                source_context=reg.get("source_context", "Prompt 1.0")
            )
            for reg in structure.variable_registry
        ]
        
        processing_time_ms = int((time.time() - start_time) * 1000)
        
        result = Prompt20Result(
            id=generate_id(),
            timestamp=get_timestamp(),
            source_prompt10_id=prompt10_result.id,
            original_text=prompt10_result.processed_text,
            template_text=structure.template_text,
            variables=variables,
            variable_registry=structure.variable_registry,
            extraction_log=structure.extraction_log,
            processing_time_ms=processing_time_ms
        )
        
        # ä¿å­˜å†å²è®°å½•
        if save_history:
            self._save_history(result)
        
        return result
    
    def _save_history(self, result: Prompt20Result):
        """ä¿å­˜ Prompt 2.0 å¤„ç†å†å²"""
        # ç»Ÿè®¡å˜é‡ç±»å‹
        type_stats = {}
        for var in result.variables:
            dtype = var.data_type
            type_stats[dtype] = type_stats.get(dtype, 0) + 1
        
        history = Prompt20History(
            id=result.id,
            timestamp=result.timestamp,
            source_prompt10_id=result.source_prompt10_id,
            input_text=result.original_text,
            template_text=result.template_text,
            variables=result.variable_registry,
            variable_count=len(result.variables),
            type_stats=type_stats,
            extraction_log=result.extraction_log,
            processing_time_ms=result.processing_time_ms
        )
        
        try:
            self.history_manager.save_prompt20_history(history)
        except Exception as e:
            warning(f"ä¿å­˜ Prompt 2.0 å†å²è®°å½•å¤±è´¥: {e}")
    
    def process(self, clean_text: str) -> PromptStructure:
        """
        ä¸»å¤„ç†æµç¨‹
        è¾“å…¥: Prompt 1.0 (å·²æ¸…æ´—æ–‡æœ¬)
        è¾“å‡º: PromptStructure (Prompt 2.0)
        """
        logger.info(f"å¼€å§‹ç»“æ„åŒ–å¤„ç†: {clean_text[:50]}...")
        self.extraction_log = []
        
        # ===== é˜¶æ®µ 2.1: è¯­ä¹‰æ‰«æä¸å®ä½“å®šä½ (LLM-Layer) =====
        raw_entities = self.llm_extractor.extract(clean_text)
        # å…¼å®¹å¤„ç†ï¼šç¡®ä¿æ˜¯åˆ—è¡¨
        if isinstance(raw_entities, str):
            raw_entities = json.loads(raw_entities)
        self._log(f"LLM è¯†åˆ«åˆ° {len(raw_entities)} ä¸ªå€™é€‰å®ä½“")
        
        # ===== é˜¶æ®µ 2.2: å¹»è§‰é˜²ç«å¢™ä¸å­˜åœ¨æ€§æ ¡éªŒ (Code-Layer) =====
        validated_entities = []
        for entity in raw_entities:
            is_valid, msg = self.firewall.validate_existence(entity, clean_text)
            if not is_valid:
                self._log(f"âŒ {msg}")
                continue
            
            # éªŒè¯ç´¢å¼•å‡†ç¡®æ€§
            if not self.firewall.validate_index(entity, clean_text):
                self._log(f"âš ï¸  ç´¢å¼•ä¸åŒ¹é…: {entity['original_text']}, å°è¯•ä¿®æ­£")
                # è‡ªåŠ¨ä¿®æ­£ç´¢å¼•
                entity = self._fix_entity_index(entity, clean_text)
            
            validated_entities.append(entity)
            self._log(f"âœ“ éªŒè¯é€šè¿‡: {entity['original_text']}")
        
        # ===== è§£å†³å®ä½“å†²çª =====
        resolved_entities = self.conflict_resolver.resolve_overlaps(validated_entities)
        self._log(f"å†²çªè§£æå®Œæˆ,ä¿ç•™ {len(resolved_entities)} ä¸ªå®ä½“")
        
        # ===== é˜¶æ®µ 2.2.5: åå¤„ç†æ ¡éªŒï¼ˆè¿‡æ»¤å›ºå®šæè¿°ï¼‰=====
        filtered_entities, filter_logs = self.entity_validator.filter_entities(resolved_entities, clean_text)
        for log in filter_logs:
            self._log(f"ğŸ” {log}")
        self._log(f"åå¤„ç†æ ¡éªŒå®Œæˆ,ä¿ç•™ {len(filtered_entities)} ä¸ªå˜é‡")
        
        # ===== é˜¶æ®µ 2.3: å¼ºç±»å‹æ¸…æ´—ä¸è½¬æ¢ (Code-Layer) =====
        variable_metas = []
        for entity in filtered_entities:  # ä¿®å¤ï¼šä½¿ç”¨è¿‡æ»¤åçš„å®ä½“
            cleaned_value, actual_type = self.type_cleaner.clean(
                entity['value'],
                entity['type']
            )

            var_meta = VariableMeta(
                name=entity['name'],
                original_text=entity['original_text'],
                value=cleaned_value,
                data_type=actual_type,
                start_index=entity['start_index'],
                end_index=entity['end_index']
            )
            variable_metas.append(var_meta)
            self._log(f"ç±»å‹è½¬æ¢: {entity['original_text']} -> {actual_type} = {cleaned_value}")
        
        # ===== é˜¶æ®µ 2.4: æ¨¡æ¿ç”Ÿæˆä¸å˜é‡æ³¨å…¥ (Code-Layer) =====
        template_text = self._generate_template(clean_text, variable_metas)
        
        # ===== ç”Ÿæˆå˜é‡æ³¨å†Œè¡¨ =====
        variable_registry = [
            {
                "variable": var.name,
                "value": var.value,
                "type": var.data_type,
                "original_text": var.original_text,
                "source_context": var.source_context
            }
            for var in variable_metas
        ]
        
        logger.info("âœ… Prompt 2.0 ç”Ÿæˆå®Œæ¯•")
        
        return PromptStructure(
            template_text=template_text,
            variable_registry=variable_registry,
            original_text=clean_text,
            extraction_log=self.extraction_log
        )
    
    def _generate_template(self, original_text: str, variables: List[VariableMeta]) -> str:
        """
        ç”Ÿæˆæ¨¡æ¿æ–‡æœ¬ (é˜²è¯¯ä¼¤ç­–ç•¥: ç´¢å¼•å®šä½æ›¿æ¢)
        """
        # æŒ‰ä½ç½®å€’åºæ’åº,ä»åå¾€å‰æ›¿æ¢ (é˜²æ­¢ç´¢å¼•åç§»)
        sorted_vars = sorted(variables, key=lambda v: v.start_index, reverse=True)
        
        result = original_text
        for var in sorted_vars:
            placeholder = f"{{{{{var.name}}}}}"
            result = (
                result[:var.start_index] + 
                placeholder + 
                result[var.end_index:]
            )
        
        return result
    
    def _fix_entity_index(self, entity: Dict, text: str) -> Dict:
        """è‡ªåŠ¨ä¿®æ­£å®ä½“ç´¢å¼•"""
        snippet = entity['original_text']
        idx = text.find(snippet)
        if idx != -1:
            entity['start_index'] = idx
            entity['end_index'] = idx + len(snippet)
        return entity
    
    def _log(self, message: str):
        """è®°å½•å¤„ç†æ—¥å¿—"""
        self.extraction_log.append(message)
        logger.info(message)


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========
def main():
    """æ¼”ç¤ºå®Œæ•´æµç¨‹"""
    
    # è¾“å…¥: Prompt 1.0 (å·²æ¸…æ´—æ–‡æœ¬)
    input_text = "è¯·ä¸ºä¸€ä½æœ‰3å¹´ç»éªŒçš„Javaç¨‹åºå‘˜ç”Ÿæˆä¸€ä¸ªä¸ºæœŸ2å‘¨çš„Pythonå­¦ä¹ è®¡åˆ’,é‡ç‚¹å…³æ³¨æ•°æ®åˆ†æã€‚"
    
    info("=" * 60)
    info("S.E.D.E Framework - Step 2: å®ä½“æŠ½å–ä¸å˜é‡å®šä¹‰")
    info("=" * 60)
    info(f"\nã€è¾“å…¥ - Prompt 1.0ã€‘:\n{input_text}\n")
    
    # åˆ›å»ºå¤„ç†å™¨ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼‰
    structurizer = PromptStructurizer(use_mock=False)  # ä½¿ç”¨çœŸå®LLM
    
    # æ–¹å¼1: ç›´æ¥å¤„ç†æ–‡æœ¬
    result = structurizer.process(input_text)
    
    # è¾“å‡ºç»“æœ
    info("\n" + "=" * 60)
    info("ã€è¾“å‡º - Prompt 2.0 æ¨¡æ¿ã€‘:")
    info("=" * 60)
    info(result.template_text)
    
    info("\n" + "=" * 60)
    info("ã€å˜é‡æ³¨å†Œè¡¨ (Variable Registry)ã€‘:")
    info("=" * 60)
    info(json.dumps(result.variable_registry, indent=2, ensure_ascii=False))
    
    info("\n" + "=" * 60)
    info("ã€å¤„ç†æ—¥å¿—ã€‘:")
    info("=" * 60)
    for log in result.extraction_log:
        info(f"  {log}")
    
    # æ–¹å¼2: ä» Prompt10Result å¤„ç†
    info("\n\n" + "=" * 60)
    info("ã€æ¼”ç¤º: ä» Prompt10Result å¤„ç†ã€‘")
    info("=" * 60)
    
    # æ¨¡æ‹Ÿä¸€ä¸ª Prompt10Result
    mock_prompt10 = Prompt10Result(
        id="test123",
        timestamp=get_timestamp(),
        mode="dictionary",
        original_text="å¸®æˆ‘æä¸ªRAGåº”ç”¨",
        processed_text=input_text,  # ä½¿ç”¨å·²å¤„ç†æ–‡æœ¬
        steps=[],
        terminology_changes={},
        status="success",
        ambiguity_detected=False
    )
    
    prompt20_result = structurizer.process_from_prompt10(mock_prompt10)
    
    info(f"\næ¥æº Prompt 1.0 ID: {prompt20_result.source_prompt10_id}")
    info(f"ç”Ÿæˆ Prompt 2.0 ID: {prompt20_result.id}")
    info(f"æ¨¡æ¿: {prompt20_result.template_text}")
    info(f"å˜é‡æ•°é‡: {len(prompt20_result.variables)}")
    
    info("\n" + "=" * 60)
    info("ã€éªŒè¯: æ¨¡æ¿å›å¡«ã€‘:")
    info("=" * 60)
    # æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ¨¡æ¿
    filled_template = result.template_text
    for var in result.variable_registry:
        placeholder = f"{{{{{var['variable']}}}}}"
        filled_template = filled_template.replace(placeholder, str(var['value']))
    info(filled_template)
    info(f"\nåŸæ–‡ä¸€è‡´æ€§: {filled_template == input_text}")


if __name__ == "__main__":
    main()



    #å¦‚ä½•ä½¿ç”¨
    # 1. åˆ›å»ºå¤„ç†å™¨
    structurizer = PromptStructurizer()

    # 2. å¤„ç†æ–‡æœ¬
    result = structurizer.process("æ‚¨çš„ Prompt 1.0 æ–‡æœ¬")

    # 3. è·å–ç»“æœ
    template = result.template_text  # å¸¦å ä½ç¬¦çš„æ¨¡æ¿
    variables = result.variable_registry  # å˜é‡å®šä¹‰è¡¨